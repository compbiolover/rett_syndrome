---
title: "111722_pnn_analysis"
author: "Andrew Willems and Tian Hong"
date: "2023-01-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = "~/Documents/Work/Phd_program/hong_lab/Projects/rett_syndrome/")
```
## Objective: Analyze cohort 111722 PNN data for collaborators

## Step 1: Load needed packages
```{r loading packages}
pacman::p_load(
  ComplexHeatmap, cowplot, circlize,
  emmeans, ggplot2, ggpubr, ggsignif, ICC, lme4,
  lmerTest, magrittr, matrixcalc, mclust, nlme, rstatix, tidyverse
)
```
## Step 2: Load in data
```{r loading data}
# Set input parameters
chs_rm <- "y" # Whether or not to remove certain channels (default is no)

# Read in the data from a CSV file
pnn_data <- read.csv("Data/111722_pnn_histogram_data/111722_pnn_histogram_data_complete.csv", sep = ",", stringsAsFactors = FALSE)

# Extract the metadata from the data and restructure it
meta_data <- t(pnn_data[1:10, 1:2981])
colnames(meta_data) <- meta_data[1, ]
meta_data <- as.data.frame(meta_data[-1, ])
meta_data$author <- rownames(meta_data)
rownames(meta_data) <- NULL
colnames(meta_data) <- c("date", "cohort", "condition", "coordinates", "hemisphere", "subregion", "rotation_x", "rotation_y", "z_position", "area", "author")

# Clean up the metadata
meta_data$cohort <- str_replace_all(meta_data$cohort, "#", "") # Remove pound sign from cohort column
meta_data$author <- str_replace_all(
  meta_data$author, # Clean up author names by removing digits and abbreviating names
  c("[0123456789]" = "", "LD\\." = "LD", "JM\\." = "JM", "RS\\." = "RS", "LD..." = "LD", "JM..." = "JM", "RS..." = "RS")
)

# Extract the expression data from the data and restructure it
expr_data <- t(pnn_data[11:266, 2:2981])
colnames(expr_data) <- paste0("ch_", 1:ncol(expr_data))
expr_data <- as.data.frame(expr_data)

# Combine the metadata and expression data into one data frame
# If chs_rm is set to "n", keep all channels, otherwise only keep channels 10-256
if (chs_rm == "n") {
  all_data <- bind_cols(meta_data, expr_data)
  rownames(all_data) <- paste0("sample_", 1:nrow(all_data))
  writeLines("No intensities were removed from the data set.")
} else {
  chs_data <- subset(expr_data, select = c(ch_10:ch_256))
  all_data <- bind_cols(meta_data, chs_data)
  rownames(all_data) <- paste0("sample_", 1:nrow(all_data))
  writeLines("Intensities 1-9 were removed from the data set.")
}
```
## Step 3a: Mclust
```{r mclust analysis}
for (s in unique(all_data$subregion)) {
  current_subregion <- filter(all_data, subregion == s)
  for (h in unique(all_data$hemisphere)) {
    current_hemisphere <- filter(current_subregion, hemisphere == h)
    for (co in unique(current_hemisphere$cohort)) {
      current_cohort <- filter(current_hemisphere, cohort == co)
      for (c in unique(current_cohort$condition)) {
        current_coordinate <- filter(current_cohort, condition == c)
        for (cor in unique(current_coordinate$coordinates)) {
          current_sample <- filter(current_coordinate, coordinates == cor)
          if (chs_rm == "n") {
            intensity_sample <- subset(current_sample, select = ch_1:ch_256)
          } else {
            intensity_sample <- subset(current_sample, select = ch_10:ch_256)
          }
          for (r in 1:nrow(intensity_sample)) {
            if (chs_rm == "n") {
              intensities <- rep(1:256, times = as.vector(unlist(intensity_sample[r, ])))
            } else {
              intensities <- rep(10:256, times = as.vector(unlist(intensity_sample[r, ])))
            }
            mod <- densityMclust(intensities, G = 2, plot = FALSE)
            res_df <- data.frame(
              condition = c,
              cohort = co,
              hemisphere = h,
              subregion = s,
              coordinates = cor,
              mean_1 = mod$parameters$mean[[1]],
              mean_2 = mod$parameters$mean[[2]],
              weight_1 = mod$parameters$pro[[1]],
              weight_2 = mod$parameters$pro[[2]]
            )
            write.csv(res_df, paste0("Outputs/pnn_analysis/density_data/111722/", c, "_", h, "_", co, "_", s, "_", cor, "_111722_intensities_removed.csv"))
          }
        }
      }
    }
  }
}
```
## Step 3b: ICC DFs
```{r icc dataframes}
if (gmm_n == 1 & chs_rm == "n") {
  all_files <- list.files("Outputs/pnn_analysis/density_data/one_cluster/no_chs_removed/")
  files_list <- vector("list", length = length(all_files))

  for (f in all_files) {
    current_file <- read.csv(paste0("Outputs/pnn_analysis/density_data/one_cluster/no_chs_removed/", f))
    files_list[[f]] <- current_file
  }
  icc_df <- bind_rows(files_list)
  icc_df <- subset(icc_df, select = c("condition", "hemisphere", "subregion", "author", "rotation_x", "area", "rotation_y", "mean_1"))
} else if (gmm_n == 1 & chs_rm == "y") {
  all_files <- list.files("Outputs/pnn_analysis/density_data/one_cluster/chs_removed/")
  files_list <- vector("list", length = length(all_files))

  for (f in all_files) {
    current_file <- read.csv(paste0("Outputs/pnn_analysis/density_data/one_cluster/chs_removed/", f))
    files_list[[f]] <- current_file
  }
  icc_df <- bind_rows(files_list)
  icc_df <- subset(icc_df, select = c("condition", "hemisphere", "subregion", "author", "rotation_x", "area", "rotation_y", "mean_1"))
} else if (gmm_n == 2 & chs_rm == "n") {
  all_files <- list.files("Outputs/pnn_analysis/density_data/two_cluster/no_chs_removed/", pattern = "sample_[0-9]_*_[A-Z]")
  files_list <- vector("list", length = length(all_files))

  for (f in all_files) {
    current_file <- read.csv(paste0("Outputs/pnn_analysis/density_data/two_cluster/no_chs_removed/", f))
    files_list[[f]] <- current_file
  }
  icc_df <- bind_rows(files_list)
  icc_df <- subset(icc_df, select = c("condition", "hemisphere", "subregion", "author", "rotation_x", "area", "rotation_y", "mean_1", "mean_2"))
} else if (gmm_n == 2 & chs_rm == "y") {
  all_files <- list.files("Outputs/pnn_analysis/density_data/two_cluster/chs_removed/")
  files_list <- vector("list", length = length(all_files))

  for (f in all_files) {
    current_file <- read.csv(paste0("Outputs/pnn_analysis/density_data/two_cluster/chs_removed/", f))
    files_list[[f]] <- current_file
  }
  icc_df <- bind_rows(files_list)
  icc_df <- subset(icc_df, select = c("condition", "hemisphere", "subregion", "author", "rotation_x", "area", "rotation_y", "mean_1", "mean_2"))
}
```
## Step 4: ICC Analysis
```{r icc analysis function}
icc_analysis <- function(data = all_data, subset_data = FALSE, subset_var = NULL, subset_val = NULL, dependent_var = "mean_2", icc_title = "ICC Analysis", icc_filename = "table", icc_path = "Outputs/pnn_analysis/icc_data/gt_tables/") {
  iccs <- list()
  returns <- list()

  if (subset_data == TRUE) {
    data <- filter(data, {{ subset_var }} == {{ subset_val }})
  }

  for (c in colnames(data)) {
    if (c == {{ dependent_var }}) {
      print("This is the dependent variable. We are skipping it")
      next
    } else {
      icc <- ICCbare(x = {{ c }}, y = {{ dependent_var }}, data = data)
      iccs[[c]] <- icc
    }
  }

  # Making a data frame
  icc_df_sub <- bind_cols(iccs)

  # Making that data frame a nicer looking table
  gt_icc <- gt(icc_df)
  gt_icc <- gt_icc %>%
    tab_header(
      title = icc_title
    ) %>%
    cols_align(
      align = "center",
      columns = c(colnames(icc_df_sub))
    ) %>%
    tab_options(heading.align = "center")


  gtsave(gt_icc, filename = paste0(icc_filename), path = paste0(icc_path))

  # Adding the outputs we want to return
  returns[["iccs"]] <- iccs

  return(returns)
}

icc_output <- suppressWarnings(icc_analysis(data = all_data, subset_data = FALSE, subset_var = NULL, subset_val = NULL, dependent_var = "mean_2", icc_title = "111722 2 Cluster Mean 2 ICC", icc_filename = "111722_all_vars_dep_var_mean_2_two_cluster_gmm.png", icc_path = "Outputs/pnn_analysis/gt_tables/"))
```
## Step 4b: P-value Analysis
```{r p-value analysis}
rate_of_false_positives <- rep(0, 3)
rate_of_false_positives[1] <- 1 - (1 - 0.05)^4
rate_of_false_positives[2] <- 1 - (1 - 0.01)^4
rate_of_false_positives[3] <- 1 - (1 - 0.001)^4

p_values <- c(0.05, 0.01, 0.001)
fp_table <- data.frame(p_values, rate_of_false_positives)
colnames(fp_table) <- c("P-value", "False Positive Rate")
fp_table <- gt(fp_table)
fp_table <- fp_table %>%
  tab_header(
    title = "Uncorrected P-value Analysis"
  ) %>%
  cols_align(
    align = "center",
    columns = c("P-value", "False Positive Rate")
  ) %>%
  fmt_percent(
    columns = "False Positive Rate",
    decimals = 1
  )

gtsave(fp_table, path = "Outputs/pnn_analysis/p_value_analysis/", filename = "p_value_analysis.png")
```
## Step 5: T-tests with ComplexHeatmap
```{r complex heatmap}
test_mat <- matrix(data = 0, nrow = 6, ncol = 6, dimnames = list(c("NW", "NH", "SWP1", "SWP5", "SHP1", "SHP5"), c("NW", "NH", "SWP1", "SWP5", "SHP1", "SHP5")))

comparisons <- list()
my_estimates <- list()
my_estimates_low <- list()
my_estimates_high <- list()
my_estimates_low_mod <- list()
my_sigs <- list()
my_t_tests <- list()
plots <- list()
my_mean <- "mean_1"
mean_title <- "Mean 1"


for (c in colnames(test_mat)) {
  for (r in rownames(test_mat)) {
    comparisons[[paste0(r, "_", c)]] <- paste0(r, "_", c)
  }
}

# Function to read in the finished files from Mclust
read_files <- function(folder_path, pattern) {
  # Get a list of all files in the folder that match the pattern
  file_list <- list.files(path = folder_path, pattern = pattern, full.names = TRUE)

  # Read in all CSV files and combine into a single dataframe
  data <- do.call(rbind, lapply(file_list, read.csv))

  return(data)
}


all_plot_data <- read_files(folder_path = "Outputs/pnn_analysis/density_data/111722/", pattern = "*.csv")
all_plot_data <- all_plot_data %>%
  select(-X) %>%
  mutate(condition = ifelse(condition == "SH P0-P1", "SHP1", condition)) %>%
  mutate(condition = ifelse(condition == "SH P0-P5", "SHP5", condition)) %>%
  mutate(condition = ifelse(condition == "SW P0-P1", "SWP1", condition)) %>%
  mutate(condition = ifelse(condition == "SW P0-P5", "SWP5", condition))


for (s in unique(all_plot_data$subregion)) {
  current_df <- filter(all_plot_data, subregion == s)
  for (c in comparisons) {
    cond_x <- strsplit(c, "_")
    cond_y <- cond_x[[1]][2]
    cond_x <- cond_x[[1]][1]
    current_df_sub <- filter(current_df, condition == cond_x | condition == cond_y)
    if (length(table(current_df_sub$condition)) < 2) {
      current_comp <- c()
      current_comp$estimate <- NA
      current_comp$p.adj.signif <- ""
      my_estimates[[paste0(cond_x, cond_y)]] <- current_comp$estimate
      my_sigs[[paste0(cond_x, cond_y)]] <- current_comp$p.adj.signif
      my_t_tests[[paste0(cond_x, "_", cond_y)]] <- c(0, 0, 0, my_mean, names(table(current_df_sub$condition)), names(table(current_df_sub$condition)), unname(table(current_df_sub$condition)), unname(table(current_df_sub$condition)), 0, 1, 0, 0, 0, "T-test", "two.sided", 1, "ns")
    } else {
      current_comp <- NULL
      # line to change mean that is tested
      current_comp <- t_test(data = current_df_sub, formula = mean_1 ~ condition, detailed = TRUE, conf.level = 0.95) %>%
        adjust_pvalue(method = "holm") %>%
        add_significance("p.adj")
      my_t_tests[[paste0(cond_x, "_", cond_y)]] <- current_comp
      my_estimates[[paste0(cond_x, "_", cond_y)]] <- current_comp$estimate
      my_sigs[[paste0(cond_x, "_", cond_y)]] <- current_comp$p.adj.signif
    }
  }

  estimates_mat <- do.call("cbind", my_estimates)
  sigs_mat <- do.call("cbind", my_sigs)
  dim(estimates_mat) <- c(6, 6)
  dim(sigs_mat) <- c(6, 6)
  dimnames(estimates_mat) <- list(rownames(test_mat), colnames(test_mat))
  dimnames(sigs_mat) <- list(rownames(test_mat), colnames(test_mat))
  lower_estimates <- lower.triangle(estimates_mat)
  upper_estimates <- upper.triangle(estimates_mat)
  lower_estimates <- lower_estimates * -1
  lower_estimates <- apply(lower_estimates, c(1, 2), as.numeric)
  indicies_to_rep <- which(lower_estimates == 0.000, arr.ind = TRUE)
  indices_to_use_in_upper <- which(upper_estimates != 0.000, arr.ind = TRUE)
  lower_estimates[indicies_to_rep] <- upper_estimates[indices_to_use_in_upper]


  p1 <- Heatmap(
    matrix = lower_estimates, show_heatmap_legend = TRUE,
    heatmap_legend_param = list(
      title = "Delta Means (x-y)",
      title_gp = gpar(
        fontsize = 16,
        fontface = "bold"
      ),
      direction = "horizontal",
      title_position = "topcenter",
      labels_gp = gpar(fontsize = 14, fontface = "bold")
    ),
    cluster_rows = FALSE,
    cluster_columns = FALSE,
    row_names_side = "left",
    column_names_centered = TRUE,
    column_names_rot = 45,
    row_order = c("SHP5", "SHP1", "SWP5", "SWP1", "NH", "NW"),
    row_title_gp = gpar(fontsize = 20, fontface = "bold"),
    row_names_gp = gpar(fontsize = 16, fontface = "bold"),
    na_col = "white", column_names_gp = gpar(
      fontsize = 16,
      fontface = "bold"
    ),
    column_title = paste0(s, " | ", mean_title),
    column_title_gp = gpar(fontsize = 22, fontface = "bold"),
    cell_fun = function(j, i, x, y, width, height, fill) {
      if (my_t_tests[[paste0(colnames(test_mat)[j], "_", rownames(test_mat)[i])]][17] < 0.05) {
        grid.text(sprintf("%s", my_t_tests[[paste0(colnames(test_mat)[j], "_", rownames(test_mat)[i])]][17]), x, y, gp = gpar(fontsize = 16))
      }
    }, rect_gp = gpar(color = "black")
  )

  p1 <- p1 %>%
    draw(heatmap_legend_side = "bottom")


  png(file = paste0("Outputs/pnn_analysis/heatmaps/subregion_", s, "_complex_heatmap_", my_mean, ".png"), units = "in", width = 6, height = 0.3937 * 6 + 0.7423, res = 600)
  p1 <- draw(p1, height = unit(1, "cm") * 6)
  draw(p1, height = unit(1, "cm") * 6)
  dev.off()


  p1 <- grid.grabExpr(draw(p1))
  plots[[s]] <- p1
}

combo_plot <- plot_grid(plotlist = plots, align = "hv", nrow = 5, ncol = 5, labels = "AUTO", label_size = 18)
save_plot(filename = paste0("Outputs/pnn_analysis/heatmaps/combo_plot_complexheatmap_", my_mean, ".png"), plot = combo_plot, ncol = 5, nrow = 5, base_asp = 1.0, bg = "white")
```

```{r braking the subregions down by hemisphere}
test_mat <- matrix(data = 0, nrow = 6, ncol = 6, dimnames = list(c("NW", "NH", "SWP1", "SWP5", "SHP1", "SHP5"), c("NW", "NH", "SWP1", "SWP5", "SHP1", "SHP5")))

comparisons <- list()
my_estimates <- list()
my_estimates_low <- list()
my_estimates_high <- list()
my_estimates_low_mod <- list()
my_sigs <- list()
my_t_tests <- list()
plots <- list()
my_mean <- "mean_1"
mean_title <- "Mean 1"


for (c in colnames(test_mat)) {
  for (r in rownames(test_mat)) {
    comparisons[[paste0(r, "_", c)]] <- paste0(r, "_", c)
  }
}

# Function to read in the finished files from Mclust
read_files <- function(folder_path, pattern) {
  # Get a list of all files in the folder that match the pattern
  file_list <- list.files(path = folder_path, pattern = pattern, full.names = TRUE)

  # Read in all CSV files and combine into a single dataframe
  data <- do.call(rbind, lapply(file_list, read.csv))

  return(data)
}


all_plot_data <- read_files(folder_path = "Outputs/pnn_analysis/density_data/111722/", pattern = "*.csv")
all_plot_data <- all_plot_data %>%
  select(-X) %>%
  mutate(condition = ifelse(condition == "SH P0-P1", "SHP1", condition)) %>%
  mutate(condition = ifelse(condition == "SH P0-P5", "SHP5", condition)) %>%
  mutate(condition = ifelse(condition == "SW P0-P1", "SWP1", condition)) %>%
  mutate(condition = ifelse(condition == "SW P0-P5", "SWP5", condition))

lh_plots <- list()
rh_plots <- list()


for (s in unique(all_plot_data$subregion)) {
  current_subregion <- filter(all_plot_data, subregion == s)
  for (h in unique(all_plot_data$hemisphere)) {
    current_df <- filter(current_subregion, hemisphere == h)
    for (c in comparisons) {
      cond_x <- strsplit(c, "_")
      cond_y <- cond_x[[1]][2]
      cond_x <- cond_x[[1]][1]
      current_df_sub <- filter(current_df, condition == cond_x | condition == cond_y)
      if (length(table(current_df_sub$condition)) < 2) {
        current_comp <- c()
        current_comp$estimate <- NA
        current_comp$p.adj.signif <- ""
        my_estimates[[paste0(cond_x, cond_y)]] <- current_comp$estimate
        my_sigs[[paste0(cond_x, cond_y)]] <- current_comp$p.adj.signif
        my_t_tests[[paste0(cond_x, "_", cond_y)]] <- c(0, 0, 0, my_mean, names(table(current_df_sub$condition)), names(table(current_df_sub$condition)), unname(table(current_df_sub$condition)), unname(table(current_df_sub$condition)), 0, 1, 0, 0, 0, "T-test", "two.sided", 1, "ns")
      } else {
        current_comp <- NULL
        # line to change mean that is tested
        current_comp <- t_test(data = current_df_sub, formula = mean_1 ~ condition, detailed = TRUE, conf.level = 0.99) %>%
          adjust_pvalue(method = "holm") %>%
          add_significance("p.adj")
        my_t_tests[[paste0(cond_x, "_", cond_y)]] <- current_comp
        my_estimates[[paste0(cond_x, "_", cond_y)]] <- current_comp$estimate
        my_sigs[[paste0(cond_x, "_", cond_y)]] <- current_comp$p.adj.signif
      }
    }

    estimates_mat <- do.call("cbind", my_estimates)
    sigs_mat <- do.call("cbind", my_sigs)
    dim(estimates_mat) <- c(6, 6)
    dim(sigs_mat) <- c(6, 6)
    dimnames(estimates_mat) <- list(rownames(test_mat), colnames(test_mat))
    dimnames(sigs_mat) <- list(rownames(test_mat), colnames(test_mat))
    lower_estimates <- lower.triangle(estimates_mat)
    upper_estimates <- upper.triangle(estimates_mat)
    lower_estimates <- lower_estimates * -1
    lower_estimates <- apply(lower_estimates, c(1, 2), as.numeric)
    indicies_to_rep <- which(lower_estimates == 0.000, arr.ind = TRUE)
    indices_to_use_in_upper <- which(upper_estimates != 0.000, arr.ind = TRUE)
    lower_estimates[indicies_to_rep] <- upper_estimates[indices_to_use_in_upper]


    p1 <- Heatmap(
      matrix = lower_estimates, show_heatmap_legend = TRUE,
      heatmap_legend_param = list(
        title = "Delta Means (x-y)",
        title_gp = gpar(
          fontsize = 16,
          fontface = "bold"
        ),
        direction = "horizontal",
        title_position = "topcenter",
        labels_gp = gpar(fontsize = 14, fontface = "bold")
      ),
      cluster_rows = FALSE,
      cluster_columns = FALSE,
      row_names_side = "left",
      column_names_centered = TRUE,
      column_names_rot = 45,
      row_order = c("SHP5", "SHP1", "SWP5", "SWP1", "NH", "NW"),
      row_title_gp = gpar(fontsize = 20, fontface = "bold"),
      row_names_gp = gpar(fontsize = 16, fontface = "bold"),
      na_col = "white", column_names_gp = gpar(
        fontsize = 16,
        fontface = "bold"
      ),
      column_title = paste0(s, " | ", mean_title, " | ", h),
      column_title_gp = gpar(fontsize = 22, fontface = "bold"),
      cell_fun = function(j, i, x, y, width, height, fill) {
        if (my_t_tests[[paste0(colnames(test_mat)[j], "_", rownames(test_mat)[i])]][17] < 0.05) {
          grid.text(sprintf("%s", my_t_tests[[paste0(colnames(test_mat)[j], "_", rownames(test_mat)[i])]][17]), x, y, gp = gpar(fontsize = 16))
        }
      }, rect_gp = gpar(color = "black")
    )

    p1 <- p1 %>%
      draw(heatmap_legend_side = "bottom")


    png(file = paste0("Outputs/pnn_analysis/heatmaps/subregion_", s, "_complex_heatmap_", my_mean, "_", h, ".png"), units = "in", width = 6, height = 0.3937 * 6 + 0.7423, res = 600)
    p1 <- draw(p1, height = unit(1, "cm") * 6)
    draw(p1, height = unit(1, "cm") * 6)
    dev.off()


    p1 <- grid.grabExpr(draw(p1))
    if (h == "LH") {
      lh_plots[[s]] <- p1
    } else {
      rh_plots[[s]] <- p1
    }
  }
}

for (h in unique(all_plot_data$hemisphere)) {
  if (h == "LH") {
    combo_plot <- plot_grid(plotlist = lh_plots, align = "hv", nrow = 5, ncol = 5, labels = "AUTO", label_size = 18)
    save_plot(filename = paste0("Outputs/pnn_analysis/heatmaps/combo_plot_complexheatmap_", my_mean, "_", h, ".png"), plot = combo_plot, ncol = 5, nrow = 5, base_asp = 1.0, bg = "white")
  } else {
    combo_plot <- plot_grid(plotlist = rh_plots, align = "hv", nrow = 5, ncol = 5, labels = "AUTO", label_size = 18)
    save_plot(filename = paste0("Outputs/pnn_analysis/heatmaps/combo_plot_complexheatmap_", my_mean, "_", h, ".png"), plot = combo_plot, ncol = 5, nrow = 5, base_asp = 1.0, bg = "white")
  }
}
```
