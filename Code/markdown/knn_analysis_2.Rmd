---
title: "knn_analysis_2"
author: "Andrew Willems and Tian Hong"
date: "2023-01-24"
output: html_document
---

```{r setup, include=FALSE}
# `knitr::opts_chunk$set(echo = TRUE)` sets the global chunk option to include the code in the output document, allowing code chunks to be executed and their results displayed.
# `knitr::opts_knit$set(root.dir = "~/Documents/Work/PhD_Program/Hong_Lab/Projects/rett_syndrome/")` sets the working directory for the R Markdown document, which is the directory where all relative file paths will be resolved.
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/Work/Phd_program/hong_lab/Projects/rett_syndrome/")
```


## Loading packages
```{r loading needed packages}
# Load packages using pacman and add documentation

suppressMessages(pacman::p_load(
  car, # Tools for performing specific statistical tests
  caret, # Tools for training and evaluating predictive models
  class, # Functions for nearest neighbor classification
  deldir, # Delaunay triangulation and Dirichlet (Voronoi) tesselation
  effectsize, # Functions for calculating standardized effect sizes
  ggforce, # Additional geometries, stats, scales and themes for ggplot2
  ggpubr, # Functions for combining multiple ggplots into a single plot
  ggsignif, # Geometries for adding significance bars to ggplot2 plots
  rstatix, # Functions for descriptive statistics and statistical tests
  readxl, # Functions for reading Excel files
  reticulate, # Interface to Python for calling Python code from R
  scales, # Functions for scaling and formatting plot axes
  tidyverse # Collection of packages for data manipulation and visualization
))

# Documentation:

# - caret: The caret package provides a set of functions for training and evaluating predictive models, including functions for data splitting, pre-processing, feature selection, model tuning, and performance evaluation.
# - class: The class package provides functions for nearest neighbor classification, including k-nearest neighbor (KNN) classification.
# - deldir: The deldir package provides functions for computing Delaunay triangulations and Dirichlet (Voronoi) tesselations, which can be used for spatial analysis and modeling.
# - effectsize: The effectsize package provides functions for calculating standardized effect sizes, which can be used to compare the strength of effects across different studies or datasets.
# - ggforce: The ggforce package provides additional geometries, stats, scales and themes for ggplot2, which can be used to create more complex and specialized plots.
# - ggpubr: The ggpubr package provides functions for combining multiple ggplots into a single plot, which can be used to compare and visualize multiple datasets or variables.
# - ggsignif: The ggsignif package provides geometries for adding significance bars to ggplot2 plots, which can be used to visualize and communicate statistical significance.
# - rstatix: The rstatix package provides functions for descriptive statistics and statistical tests, including t-tests, ANOVA, and correlation analysis.
# - readxl: The readxl package provides functions for reading Excel files, which can be used to import data from spreadsheets into R.
# - reticulate: The reticulate package provides an interface to Python for calling Python code from R, which can be useful for accessing Python libraries or using Python code within R scripts.
# - scales: The scales package provides functions for scaling and formatting plot axes, which can be used to customize the appearance of plots.
# - tidyverse: The tidyverse is a collection of packages for data manipulation and visualization, including dplyr, ggplot2, tidyr, and other packages that follow the "tidy" data philosophy.
```

## Loading data
```{r loading data}
## Read data
naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT") %>%
  rename_all(~ c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")) %>%
  mutate(condition = "WT")

naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET") %>%
  rename_all(~ c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")) %>%
  mutate(condition = "HET")

sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT") %>%
  rename_all(~ c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")) %>%
  mutate(condition = "WT")

sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET") %>%
  rename_all(~ c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")) %>%
  mutate(condition = "HET")

## Merge data and create condition_spec variable
merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het) %>%
  mutate(condition_spec = str_extract(image, "(NW|NH|SW|SH)")) %>%
  mutate(condition_spec = factor(condition_spec, levels = c("NW", "SW", "NH", "SH"))) %>%
  filter(image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")

## Grouping the data by images and then splitting them into seperate images for
## further analysis
all_imgs <- merged_df %>%
  group_by(image) %>%
  group_split(merged_df)


## Remove intermediate files to keep environment tidy
rm(naive_df_het, naive_df_wt, sur_df_het, sur_df_wt)
```


## Cell count plot
```{r cell count plot}
p1 <- ggplot(data = merged_df, aes(x = condition_spec, fill = mecp2_p)) +
  geom_bar(position = position_dodge()) +
  theme(
    text = element_text(family = "Arial"),
    panel.background = element_blank(),
    axis.text = element_text(size = 22),
    axis.ticks.y = element_blank(),
    panel.grid.major.y = element_line(colour = "grey", linetype = "solid"),
    legend.position = "bottom"
  ) +
  xlab("Condition") +
  ylab("Cell Count") +
  scale_fill_manual(values = c("#4682b4", "#F4A460"), name = "MECP2 Status", labels = c("No expression", "Expression"))
p1

## Saving the plot
ggsave(
  filename = "Figures/knn_analysis/condition_vs_cell_count.png",
  plot = p1,
  device = "png", dpi = 600,
  width = 7.5, height = 7.5,
  units = "in"
)

# Removing un-needed plots
rm(p1)
```

```{r spatial plot with each image as plot}
img_counts <- merged_df %>% count(image)

merged_df <- merged_df %>%
  mutate(image = case_when(
    grepl("MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23", image) ~ "NH_126_z13_23",
    grepl("z1-z10_MAX_16-bit_SW-RW9-1.3-Map128_561-60_G150_E100", image) ~ "SW_128_z1_10",
    grepl("z11-z20_NW-RW10-2.2-Map128_MergedMC", image) ~ "NW_128_z11_20",
    grepl("z12-z21_SW-LW10-2.1-Map128_MergedMC", image) ~ "SW_128_z12_21",
    grepl("z13-23_MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100", image) ~ "NH_126_z13_23",
    grepl("z15-z24_SH-RW10-2.2-Map127_MergedMC", image) ~ "SH_127_z15_24",
    grepl("z16-z25_MAX_16-bit_NH-RW9-1.2-Map128_561-60_G150_E100", image) ~ "NH_128_z16_25",
    grepl("z19-z28_SH-LW10-2.2-Map128_MergedMC", image) ~ "SH_128_z19_28",
    grepl("z23-z32_SH-LW10-1.2-Map128_MergedMC", image) ~ "SH_128_z23_32",
    grepl("z29-z38_SH-RW10-1.2-Map127_MergedMC", image) ~ "SH_127_z29_38",
    grepl("z3-z12_MAX_16-bit_SW-LW9-3.2-Map128_561-60_G150_E100", image) ~ "SW_128_z3_12",
    grepl("z31-z40_MAX_16-bit_NH-LW8-1.2-Map127_561-60_G150_E100", image) ~ "NH_127_z31_40",
    grepl("z31-z40_NW-LW9-1.2-Map128_MergedMC", image) ~ "NW_128_z31_40",
    grepl("z41-z50_SW-RW9-1.2-Map128_MergedMC", image) ~ "SW_128_z41_50",
    grepl("z5-z14_NW-RW10-2.3-Map128_MergedMC", image) ~ "NW_128_z5_14",
    grepl("z5-z14_NW-RW10-2.3-Map128_MergedMC", image) ~ "NW_128_z5_14",
    grepl("z6-z15_NW-LW9-1.4-Map128_MergedMC", image) ~ "NW_128_z6_15",
    grepl("z8-z17_MAX_16-bit_NH-RW9-1.4-Map128_561-60_G150_E100z8-z17", image) ~ "NH_128_z8_17",
    grepl("z16-z25_MAX_16-bit_NH-RW9-1.2-Map128_561-60_G150_E100", image) ~ "NH_128_z16_25",
    grepl("z19-z28_SH-LW10-2.2-Map128_MergedMC", image) ~ "SH_128_z19_28",
    grepl("z23-z32_SH-LW10-1.2-Map128_MergedMC", image) ~ "SH_128_z23_32",
    grepl("z29-z38_SH-RW10-1.2-Map127_MergedMC", image) ~ "SH_127_z29_38",
    grepl("z3-z12_MAX_16-bit_SW-LW9-3.2-Map128_561-60_G150_E100", image) ~ "SW_128_z3_12",
    grepl("z31-z40_MAX_16-bit_NH-LW8-1.2-Map127_561-60_G150_E100", image) ~ "NH_127_z31_40",
    grepl("z31-z40_NW-LW9-1.2-Map128_MergedMC", image) ~ "NW_128_z31_40",
    grepl("z41-z50_SW-RW9-1.2-Map128_MergedMC", image) ~ "SW_128_z41_50",
    grepl("z5-z14_NW-RW10-2.3-Map128_MergedMC", image) ~ "NW_128_z5_14",
    grepl("z6-z15_NW-LW9-1.4-Map128_MergedMC", image) ~ "NW_128_z6_15",
    grepl("z8-z17_MAX_16-bit_NH-RW9-1.4-Map128_561-60_G150_E100z8-z17", image) ~ "NH_128_z8_17",
    TRUE ~ image
  ))





p1 <- merged_df %>%
  group_by(image) %>%
  ggplot(aes(x = x, y = y, fill = condition_spec, color = condition_spec)) +
  geom_point(size = 3) +
  theme(
    panel.background = element_blank(),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 22),
    axis.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 14),
    panel.spacing = unit(5, "mm"),
    strip.text = element_text(face = "bold", size = 14),
    legend.position = "bottom",
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14),
    panel.border = element_rect(color = "black", fill = NA)
  ) +
  ggtitle("Images") +
  xlab("X (coordinate)") +
  ylab("Y (coordinate)") +
  scale_fill_discrete(name = "Condition") +
  scale_color_discrete(name = "Condition") +
  scale_shape_manual(name = "MECP2\nStatus", values = c(15, 16)) + # Change the shapes manually
  facet_wrap(mecp2_p ~ image, scales = "free", nrow = 8, ncol = 8) +
  scale_y_continuous(expand = c(0.01, 0.01), limits = c(0, 400)) +
  scale_x_continuous(expand = c(0.03, 0.03))

p1

# Saving the plot
ggsave(filename = "spatial_plot.png", plot = p1, units = "in", width = 22, height = 22, dpi = 600, path = "Outputs/knn_analysis/plots/", device = "png")
ggsave(filename = "spatial_plot.svg", plot = p1, units = "in", width = 22, height = 22, dpi = 600, path = "Outputs/knn_analysis/plots/", device = "svg")
rm(p1)
```

## KNN analysis 
```{r knn functions}
nearest_neighbors <- function(data, observation, num_neighbors, distance_func, p_val = NULL, apply_intensity = TRUE, intensity_data = my_x, p_only = TRUE, calc_mean_intensity = FALSE, custom_neighbors = NULL, random_num_neighbors = FALSE) {
  #' Nearest neighbors function with options to calculate mean neighborhood intensity
  #' @param data A data frame or matrix of predictor variables for the neighbors (required)
  #' @param observation A data frame or matrix of predictor variables for the observation of interest (required)
  #' @param num_neighbors An integer specifying the maximum number of nearest neighbors to find (required)
  #' @param distance_func A function to calculate distance between neighbors (e.g., euclidean_distance) (required)
  #' @param p_val An optional numeric value for Minkowski distance calculation (default: NULL)
  #' @param apply_intensity A logical indicating if intensity information should be used (default: TRUE)
  #' @param intensity_data A data frame or matrix containing intensity information (default: my_x)
  #' @param p_only A logical indicating if only 'P' neighbors should be used (default: TRUE)
  #' @param calc_mean_intensity A logical indicating if the mean intensity of the neighborhood should be calculated (default: FALSE)
  #' @param custom_neighbors An optional numeric vector of pre-selected neighbor indices (default: NULL)
  #' @param random_num_neighbors A logical indicating if the function should select a random number of neighbors equal to k (default: FALSE)
  #' @return A list containing information about the nearest neighbors:
  #'         - neighbor_indices: Numeric vector of neighbor indices
  #'         - distances: Numeric vector of distances between the observation and neighbors
  #'         - mean_distance: Mean of the updated distances
  #'         - distances_updated: Numeric vector of updated distances considering intensity information


  # Check the number of observations is the same
  if (ncol(data) != ncol(observation)) {
    stop("Data must have the same number of variables")
  }

  # Calculate distance, considering p for Minkowski
  dist <- if (is.null(p_val)) apply(data, 1, distance_func, observation) else apply(data, 1, distance_func, observation, p_val)

  # Select neighbors and determine distances
  if (random_num_neighbors) {
    neighbor_indices <- sample(nrow(data), num_neighbors)
  } else if (!is.null(custom_neighbors)) {
    neighbor_indices <- custom_neighbors
  } else {
    neighbor_indices <- which(dist %in% sort(dist)[1:num_neighbors])
  }
  distances <- dist[neighbor_indices]

  # Calculate distances with intensity information
  if (apply_intensity) {
    intensity_info <- intensity_data[neighbor_indices, ]
    distances_updated <- rescale(distances * intensity_info$mean, to = c(0, 1))

    # Calculate updated distances with intensity information for just P neighbors
    if (p_only) {
      intensity_info <- filter(intensity_info, mecp2_p == "P")
      if (nrow(intensity_info) == 0) {
        writeLines("This sample has only N neighbors.\nIt is being excluded from this analysis.")
      }
    }
  }

  # Calculate mean neighborhood intensity
  if (calc_mean_intensity) {
    ret <- mean(intensity_info$mean)
  } else {
    ret <- list(neighbor_indices, distances, mean(distances_updated), distances_updated)
  }

  return(ret)
}

euclidean_distance <- function(a, b) {
  #  We check that they have the same number of observation
  if (length(a) == length(b)) {
    sqrt(sum((a - b)^2))
  } else {
    stop("Vectors must be of the same length")
  }
}


# For 3D data
euclidean_distance_3d <- function(x1, y1, z1, x2, y2, z2) {
    sqrt(sum((x2-x1)^2 + (y2-y1)^2 + (z2-z1)^2))
    # sqrt(sum((a - b)^2 + (a - c)^2 + (b - c)^2))
  }
```

```{r knn analysis with 1 neighbor}
p_score <- 0
n_score <- 0


merged_df <- merged_df %>% group_by(image)
all_imgs <- merged_df %>% group_split(merged_df)

for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$knn_1_label <- rep(0, nrow(current_img))
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)

    my_ind <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 1, distance_func = euclidean_distance, apply_intensity = TRUE)[[1]]
    my_dist <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 1, distance_func = euclidean_distance, apply_intensity = TRUE)[[2]]
    if (using_intensity == TRUE) {
      my_add_p_score <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 3, distance_func = euclidean_distance, apply_intensity = TRUE)[[3]]
      mod_dists <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 3, distance_func = euclidean_distance, apply_intensity = TRUE)[[4]]
    }
    print(paste0("The nearest neighbor of image ", my_obs$image, " with ROI ID ", my_obs$id, " has an MECP2_P status of: ", as.matrix(my_x[my_ind, 5])))
    nn_status <- as.data.frame(my_x[my_ind, 5])
    nn_info <- as.data.frame(my_x[my_ind, 1:11])
    if (dim(nn_status)[1] == 0) {
      next
    } else {
      if (nn_status[1, ] == "P") {
        current_img[r, "knn_1_label"] <- 1
        p_score <- p_score + 1
        if (my_add_p_score == 0) {
          next
        } else {
          p_score <- (nn_status$mecp2_p == "P") / my_add_p_score
        }
      } else {
        current_img[r, "knn_1_label"] <- 0
        n_score <- n_score + 1
      }
    }
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/img_knn_1_", i, "_df_16_bit.csv"))
  write.csv(p_score, paste0("Outputs/knn_analysis/data/img_knn_1_", i, "_df_p_score_16_bit.csv"))
  write.csv(n_score, paste0("Outputs/knn_analysis/data/img_knn_1_", i, "_df_n_score_16_bit.csv"))
}

all_dfs <- vector(mode = "list", length = 15)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/img_knn_1_", i, "_df_16_bit.csv"))
  all_dfs[[i]] <- current_df
}

knn_1_df <- bind_rows(all_dfs)

knn_1_df$condition_spec <- factor(knn_1_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))

# T-tests
knn_1_df$p_num <- knn_1_df$mecp2_p
knn_1_df$p_num <- gsub(x = knn_1_df$p_num, replacement = 1, pattern = "P")
knn_1_df$p_num <- gsub(x = knn_1_df$p_num, replacement = 0, pattern = "N")
knn_1_df$p_num <- as.numeric(knn_1_df$p_num)
knn_1_df$knn_1_label <- as.numeric(knn_1_df$knn_1_label)

# T-test by condition comparing N vs P MECP2 status within condition
status_v_score <- knn_1_df %>%
  group_by(condition_spec) %>%
  t_test(data = ., knn_1_label ~ p_num, detailed = TRUE) %>%
  adjust_pvalue(method = "holm") %>%
  add_significance("p.adj")

# T-test comparing conditions to scoring label
cond_v_score <- t_test(data = knn_1_df, knn_1_label ~ condition_spec, p.adjust.method = "holm", detailed = TRUE)

# Adding p-value to plot
p0 <- ggplot(data = knn_1_df, aes(x = condition_spec, y = knn_1_label, fill = mecp2_p)) +
  geom_violin(trim = FALSE, scale = "area") +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2)) +
  theme(
    text = element_text(family = "Arial"),
    panel.background = element_blank(),
    axis.text = element_text(size = 22),
    axis.ticks.y = element_blank(),
    panel.grid.major.y = element_line(colour = "grey", linetype = "solid")
  ) +
  xlab("Condition") +
  ylab("1NN score ") +
  scale_fill_manual(values = c("#4682b4", "#F4A460"), name = "MECP2\nStatus") +
  geom_signif(y_position = c(1.8, 1.8, 1.8, 1.8), xmin = c(0.8, 1.8, 2.8, 3.8), xmax = c(1.2, 2.2, 3.2, 4.2), annotations = c("ns", "ns", "*", "ns"))

p0

ggsave(
  plot = p0, filename = "Outputs/knn_analysis/plots/knn_analysis/knn_1.png",
  device = "png", dpi = 600,
  width = 7.5, height = 7.5,
  units = "in"
)
```

```{r knn analysis with 3 neighbors}
p_score <- 0
n_score <- 0
using_intensity <- TRUE

naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
all_imgs <- merged_df %>% group_split(merged_df)

for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$knn_3_label <- rep(0, nrow(current_img))
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)
    my_ind <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 3, distance_func = euclidean_distance, apply_intensity = TRUE, p_only = TRUE)[[1]]

    my_dist <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 3, distance_func = euclidean_distance, apply_intensity = TRUE)[[2]]
    if (using_intensity == TRUE) {
      my_add_p_score <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 3, distance_func = euclidean_distance, apply_intensity = TRUE)[[3]]
      dist_updated <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 3, distance_func = euclidean_distance, apply_intensity = TRUE)[[4]]
    }
    print(paste0("The nearest neighbor of image ", my_obs$image, " with ROI ID ", my_obs$id, " has an MECP2_P status of: ", as.matrix(my_x[my_ind, 5])))
    nn_status <- as.data.frame(my_x[my_ind, 5])
    nn_info <- as.data.frame(my_x[my_ind, 1:11])
    if (using_intensity == TRUE) {
      if (my_add_p_score == 0) {
        next
      } else {
        current_img[r, "knn_3_label"] <- (sum((nn_status$mecp2_p == "P")) / 3) / my_add_p_score
      }
    } else {
      current_img[r, "knn_3_label"] <- sum((nn_status$mecp2_p == "P")) / 3
    }
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/img_knn_3_", i, "_df_16_bit_intensity.csv"))
}



all_dfs <- vector(mode = "list", length = 15)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/img_knn_3_", i, "_df_16_bit_intensity.csv"))
  all_dfs[[i]] <- current_df
}

knn_3_df <- bind_rows(all_dfs)

knn_3_df$condition_spec <- factor(knn_3_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))

# T-tests
knn_3_df$p_num <- knn_3_df$mecp2_p
knn_3_df$p_num <- gsub(x = knn_3_df$p_num, replacement = 1, pattern = "P")
knn_3_df$p_num <- gsub(x = knn_3_df$p_num, replacement = 0, pattern = "N")
knn_3_df$p_num <- as.numeric(knn_3_df$p_num)
knn_3_df$knn_3_label <- as.numeric(knn_3_df$knn_3_label)

# T-test by condition comparing N vs P MECP2 status within condition
status_v_score <- knn_3_df %>%
  group_by(condition_spec) %>%
  t_test(data = ., knn_3_label ~ p_num, detailed = TRUE) %>%
  adjust_pvalue(method = "holm") %>%
  add_significance("p.adj")

# T-test comparing conditions to scoring label
cond_v_score <- t_test(data = knn_3_df, knn_3_label ~ condition_spec, p.adjust.method = "holm", detailed = TRUE)

# Adding p-value to plot
p1 <- ggplot(data = knn_3_df, aes(x = condition_spec, y = knn_3_label, fill = mecp2_p)) +
  geom_violin(trim = FALSE, scale = "area") +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2)) +
  theme(
    text = element_text(family = "Arial"),
    panel.background = element_blank(),
    axis.text = element_text(size = 22),
    axis.ticks.y = element_blank(),
    panel.grid.major.y = element_line(colour = "grey", linetype = "solid")
  ) +
  xlab("Condition") +
  ylab("3NN score ") +
  scale_fill_manual(values = c("#4682b4", "#F4A460"), name = "MECP2\nStatus") +
  geom_signif(y_position = c(4.0, 4.0, 4.0, 4.0), xmin = c(0.8, 1.8, 2.8, 3.8), xmax = c(1.2, 2.2, 3.2, 4.2), annotations = c("ns", "**", "**", "ns"))

p1

ggsave(
  plot = p1, filename = "Outputs/knn_analysis/plots/knn_analysis/knn_3.png",
  device = "png", dpi = 600,
  width = 7.5, height = 7.5,
  units = "in"
)
```

```{r knn analysis with 5 neighbors}
p_score <- 0
n_score <- 0
using_intensity <- TRUE

naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
all_imgs <- merged_df %>% group_split(merged_df)

for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$knn_5_label <- rep(0, nrow(current_img))

  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)

    my_ind <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 5, distance_func = euclidean_distance, apply_intensity = TRUE, p_only = TRUE)[[1]]
    my_dist <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 5, distance_func = euclidean_distance, apply_intensity = TRUE)[[2]]
    if (using_intensity == TRUE) {
      my_add_p_score <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 5, distance_func = euclidean_distance, apply_intensity = TRUE)[[3]]
      mod_dists <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 5, distance_func = euclidean_distance, apply_intensity = TRUE)[[4]]
    }

    print(paste0("The nearest neighbor of image ", my_obs$image, " with ROI ID ", my_obs$id, " has an MECP2_P status of: ", as.matrix(my_x[my_ind, 5])))
    nn_status <- as.data.frame(my_x[my_ind, 5])
    nn_info <- as.data.frame(my_x[my_ind, 1:11])

    if (using_intensity == TRUE) {
      if (my_add_p_score == 0) {
        next
      } else {
        current_img[r, "knn_5_label"] <- (sum((nn_status$mecp2_p == "P")) / 5) / my_add_p_score
      }
    } else {
      current_img[r, "knn_5_label"] <- sum((nn_status$mecp2_p == "P")) / 5
    }
  }

  write.csv(current_img, paste0("Outputs/knn_analysis/data/img_knn_5_", i, "_df_16_bit_intensity.csv"))
}


all_dfs <- vector(mode = "list", length = 15)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/img_knn_5_", i, "_df_16_bit_intensity.csv"))
  all_dfs[[i]] <- current_df
}

knn_5_df <- bind_rows(all_dfs)

knn_5_df$condition_spec <- factor(knn_5_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))

# T-tests
knn_5_df$p_num <- knn_5_df$mecp2_p
knn_5_df$p_num <- gsub(x = knn_5_df$p_num, replacement = 1, pattern = "P")
knn_5_df$p_num <- gsub(x = knn_5_df$p_num, replacement = 0, pattern = "N")
knn_5_df$p_num <- as.numeric(knn_5_df$p_num)
knn_5_df$knn_5_label <- as.numeric(knn_5_df$knn_5_label)

# T-test by condition comparing N vs P MECP2 status within condition
status_v_score <- knn_5_df %>%
  group_by(condition_spec) %>%
  t_test(data = ., knn_5_label ~ p_num, detailed = TRUE) %>%
  adjust_pvalue(method = "holm") %>%
  add_significance("p.adj")

# T-test comparing conditions to scoring label
cond_v_score <- t_test(data = knn_5_df, knn_5_label ~ condition_spec, p.adjust.method = "holm", detailed = TRUE)

# Adding p-value to plot
p2 <- ggplot(data = knn_5_df, aes(x = condition_spec, y = knn_5_label, fill = mecp2_p)) +
  geom_violin(trim = FALSE, scale = "area") +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2)) +
  theme(
    text = element_text(family = "Arial"),
    panel.background = element_blank(),
    axis.text = element_text(size = 22),
    axis.ticks.y = element_blank(),
    panel.grid.major.y = element_line(colour = "grey", linetype = "solid")
  ) +
  xlab("Condition") +
  ylab("5NN score ") +
  scale_fill_manual(values = c("#4682b4", "#F4A460"), name = "MECP2\nStatus") +
  geom_signif(y_position = c(5.5, 5.5, 5.5, 5.5), xmin = c(0.8, 1.8, 2.8, 3.8), xmax = c(1.2, 2.2, 3.2, 4.2), annotations = c("ns", "***", "*", "ns"))

p2

ggsave(
  plot = p2, filename = "Outputs/knn_analysis/plots/knn_analysis/knn_5.png",
  device = "png", dpi = 600,
  width = 7.5, height = 7.5,
  units = "in"
)
```

```{r knn analysis with 21 neighbors}
p_score <- 0
n_score <- 0
using_intensity <- TRUE

naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
all_imgs <- merged_df %>% group_split(merged_df)

for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$knn_21_label <- rep(0, nrow(current_img))
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)

    my_ind <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 21, distance_func = euclidean_distance, apply_intensity = TRUE)[[1]]
    my_dist <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 21, distance_func = euclidean_distance, apply_intensity = TRUE)[[2]]
    if (using_intensity == TRUE) {
      my_add_p_score <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 21, distance_func = euclidean_distance, apply_intensity = TRUE)[[3]]
      mod_dists <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = 21, distance_func = euclidean_distance, apply_intensity = TRUE)[[4]]
    }
    print(paste0("The nearest neighbor of image ", my_obs$image, " with ROI ID ", my_obs$id, " has an MECP2_P status of: ", as.matrix(my_x[my_ind, 5])))
    nn_status <- as.data.frame(my_x[my_ind, 5])
    nn_info <- as.data.frame(my_x[my_ind, 1:11])
    if (using_intensity == TRUE) {
      if (my_add_p_score == 0) {
        next
      } else {
        current_img[r, "knn_21_label"] <- (sum((nn_status$mecp2_p == "P")) / 21) / my_add_p_score
      }
    } else {
      current_img[r, "knn_21_label"] <- sum((nn_status$mecp2_p == "P")) / 21
    }
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/img_knn_21_", i, "_df_16_bit_intensity.csv"))
}



all_dfs <- vector(mode = "list", length = 15)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/img_knn_21_", i, "_df_16_bit_intensity.csv"))
  all_dfs[[i]] <- current_df
}

knn_21_df <- bind_rows(all_dfs)

knn_21_df$condition_spec <- factor(knn_21_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))

# T-tests
knn_21_df$p_num <- knn_21_df$mecp2_p
knn_21_df$p_num <- gsub(x = knn_21_df$p_num, replacement = 1, pattern = "P")
knn_21_df$p_num <- gsub(x = knn_21_df$p_num, replacement = 0, pattern = "N")
knn_21_df$p_num <- as.numeric(knn_21_df$p_num)
knn_21_df$knn_21_label <- as.numeric(knn_21_df$knn_21_label)

# T-test by condition comparing N vs P MECP2 status within condition
status_v_score <- knn_21_df %>%
  group_by(condition_spec) %>%
  t_test(data = ., knn_21_label ~ p_num, detailed = TRUE) %>%
  adjust_pvalue(method = "holm") %>%
  add_significance("p.adj")

# T-test comparing conditions to scoring label
cond_v_score <- t_test(data = knn_21_df, knn_21_label ~ condition_spec, p.adjust.method = "holm", detailed = TRUE)

# Adding p-value to plot
p3 <- ggplot(data = knn_21_df, aes(x = condition_spec, y = knn_21_label, fill = mecp2_p)) +
  geom_violin(trim = FALSE, scale = "area") +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2)) +
  theme(
    text = element_text(family = "Arial"),
    panel.background = element_blank(),
    axis.text = element_text(size = 22),
    axis.ticks.y = element_blank(),
    panel.grid.major.y = element_line(colour = "grey", linetype = "solid")
  ) +
  xlab("Condition") +
  ylab("21NN score ") +
  scale_fill_manual(values = c("#4682b4", "#F4A460"), name = "MECP2\nStatus") +
  geom_signif(y_position = c(8.5, 8.5, 8.5, 8.5), xmin = c(0.8, 1.8, 2.8, 3.8), xmax = c(1.2, 2.2, 3.2, 4.2), annotations = c("ns", "**", "****", "ns"))

p3

ggsave(
  plot = p3, filename = "Outputs/knn_analysis/plots/knn_analysis/knn_21.png",
  device = "png", dpi = 600,
  width = 7.5, height = 7.5,
  units = "in"
)
```

```{r arrange all knn plots}
combo_plot <- ggarrange(p0, p1, p2, p3, ncol = 2, nrow = 2, labels = "AUTO", legend = "right", common.legend = TRUE)
combo_plot <- annotate_figure(combo_plot, top = text_grob("KNN Analysis", face = "bold", size = 14))
```

```{r saving combo plot}
ggsave(
  plot = combo_plot, filename = "knn_combo_plot_new_intensity_information.png", device = "png", width = 10,
  height = 10, units = "in", dpi = 600, path = "Outputs/knn_analysis/plots/knn_analysis/",
  bg = "white"
)
```

## Intensity vs. mean intensity of neighbors correlation analysis (+ neighbors only)
```{r doing intensity vs mean intensity of  + neighbors correlation analysis}
p_score <- 0
n_score <- 0
k_n <- 5
file_type_used <- "png"
# pearson, kendall, or spearman
stat_used <- "spearman"
# reg.line or loess
fit_line <- "reg.line"
using_intensity <- FALSE

naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
# Filtering to just P annotated cells
merged_df <- filter(merged_df, mecp2_p == "P")

all_imgs <- merged_df %>% group_split(merged_df)

img_means <- c()
for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
  # Each row in an image is a cell
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)
    current_cell_neighbor_mean <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = k_n, distance_func = euclidean_distance, apply_intensity = TRUE, p_only = TRUE, calc_mean_intensity = TRUE)
    img_means <- c(img_means, current_cell_neighbor_mean)
    current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis.csv"))
  img_means <- c()
}

all_dfs <- vector(mode = "list", length = 16)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis.csv"))
  all_dfs[[i]] <- current_df
}

mean_neighbor_df <- bind_rows(all_dfs)

mean_neighbor_df$condition_spec <- factor(mean_neighbor_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))

# Filtering all cells that have NA as their mean neighborhood intensity (because all neighbors were N annotated)
mean_neighbor_df <- filter(mean_neighbor_df, !is.na(mean_neighbor_df$positive_neighborhood_mean))

p1 <- ggscatter(
  data = mean_neighbor_df,
  x = "mean", y = "positive_neighborhood_mean",
  conf.int = FALSE,
  cor.coef = TRUE,
  shape = 21,
  color = "black",
  fill = "black",
  alpha = 0.5,
  cor.method = stat_used,
  xlab = "Mean Intensity of Cells",
  ylab = "Mean MECP2+\nNeighborhood Intensity",
  ellipse = TRUE,
  mean.point = TRUE,
  cor.coeff.args = list(method = stat_used, label.x = 3000)
)

p2 <- ggpar(p1,
  legend = "right",
  legend.title = "MECP2\nStatus",
  palette = c("#4682b4", "#F4A460"),
  main = paste0("KNN = ", k_n, " | All Conditions & Images | ", stat_used),
  font.main = c(16, "bold"),
  font.x = c(14, "bold"),
  font.y = c(14, "bold")
)

p3 <- p2 + stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")),
  label.x = 3000,
  label.y = 3500
)
```

```{r each condition neighborhood analysis knn}
plots <- list()


for (c in unique(mean_neighbor_df$condition_spec)) {
  current_cond <- filter(mean_neighbor_df, condition_spec == c)
  current_cond_p <- filter(current_cond, mecp2_p == "P")

  # Set ellipse and mean.point to TRUE when doing mixed cell analysis
  # Set them to FALSE for when cells are all N or all P
  # Set alpha to 0.5 when doing mixed group analysis, 1 when cells
  # all have the same annotation
  # Set fill to mecp2_p when examining mixed cell populations
  # Set fill to black when examining datasets that have one cell annotation
  # Set cor.coef to TRUE when in single annotation situations, FALSE otherwise
  # Comment out p2-p5 when examining single annotation populations, use otherwise
  p1 <- ggscatter(
    data = current_cond_p,
    x = "mean", y = "positive_neighborhood_mean",
    conf.int = TRUE,
    cor.coef = TRUE,
    cor.coeff.args = list(
      method = "spearman",
      label.x = 2000, label.sep = "\n",
      cor.coef.name = "rho"
    ),
    parse = TRUE,
    cor.coef.size = 10,
    shape = 21,
    size = 2.5,
    add = fit_line,
    add.params = list(
      color = "black",
      fill = "grey"
    ),
    repel = TRUE,
    label.rectangle = TRUE,
    color = "black",
    fill = "black",
    alpha = 1,
    cor.method = stat_used,
    xlab = "Mean Intensity of Cells",
    ylab = "Mean MECP2+\nNeighborhood Intensity",
    ellipse = FALSE,
    mean.point = FALSE
  )

  # p2 for the single annotation context
  p2 <- ggpar(p1,
    title = paste0("K = ", k_n, " | ", c),
    font.main = c(20, "bold"),
    font.x = c(18, "bold"),
    font.y = c(18, "bold"),
    ggtheme = theme(plot.title = element_text(hjust = 0.5))
  )

  p2 <- p2 +
    theme(
      axis.line = element_line(linewidth = 1.5, lineend = "round"),
      axis.text = element_text(size = 18), axis.ticks = element_line(linewidth = 0.2),
      plot.subtitle = element_text(face = "italic")
    ) +
    scale_x_continuous(limits = c(0, 4500)) +
    scale_y_continuous(limits = c(0, 2500))

  # For adding density-based contours. Comment out if not wanting countours
  p2 <- p2 +
    geom_density2d(aes(colour = ..level..), linewidth = 0.7, n = 100) +
    scale_colour_gradient(low = "blue", high = "red") +
    theme(legend.position = "none")



  # p2 <- ggpar(p1,
  #   legend = "none",
  #   legend.title = "MECP2\nStatus",
  #   palette = c("#4682b4", "#F4A460"),
  #   title = paste0("KNN = ", k_n, " | ", c, " | Spearman"),
  #   font.main = c(16, "bold"),
  #   font.x = c(14, "bold"),
  #   font.y = c(14, "bold"),
  #   ggtheme = theme(plot.title = element_text(hjust = 0.5))
  # )

  # Change to current_cond_p for p-cell only analysis in mixed neighborhoods
  # Change to current_cond for when there are only p-cells in the dataset
  # p3 <- p2 + stat_cor(aes(label = paste(..rr.label..)),
  #   label.x = 2500,
  #   label.y = 3000,
  #   method = "spearman",
  #   data = current_cond
  # )

  # p4 <- p3 + stat_cor(aes(label = paste(..r.label..)),
  #   method = "spearman",
  #   data = current_cond,
  #   p.accuracy = 0.001,
  #   r.accuracy = 0.01,
  #   label.x = 2500,
  #   label.y = 3150
  # )
  #
  # p5 <- p4 + stat_cor(aes(label = paste(..p.label..)),
  #   method = "spearman",
  #   data = current_cond,
  #   p.accuracy = 0.001,
  #   r.accuracy = 0.01,
  #   label.x = 2500,
  #   label.y = 2850
  # )

  # Change to p2 when in a single annotation context, p5 otherwise
  ggsave(plot = p2, filename = paste0("knn_", k_n, "_", c, "_positive_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = file_type_used, dpi = 600, width = 8, height = 8, units = "in")

  # Change to p2 for single annotation case, p5 otherwise
  plots[[paste0(c)]] <- p2
}

# Combo plot
combo_plot <- ggarrange(
  plots$NW,
  plots$SW,
  plots$NH,
  plots$SH,
  ncol = 2,
  nrow = 2,
  labels = "AUTO",
  align = "hv",
  legend = "none",
  common.legend = TRUE,
  font.label = list(
    size = 18,
    face = "bold"
  )
)

ggsave(plot = combo_plot, filename = paste0("knn_", k_n, "_combo_plot_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_with_contours.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = file_type_used, dpi = 600, width = 16, height = 16, units = "in", bg = "white")
```

```{r k 1 to k 15 analysis and plot}
p_score <- 0
n_score <- 0
k_ns <- seq(1, 15, 1)
file_type_used <- "png"
# pearson, kendall, or spearman
stat_used <- "spearman"
# reg.line or loess
fit_line <- "reg.line"
using_intensity <- FALSE

naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
# Filtering to just P annotated cells
merged_df <- filter(merged_df, mecp2_p == "P")
# Filtering to just NH and SH cells for the k 1 to k 15 scan
merged_df <- filter(merged_df, condition_spec == "NH" | condition_spec == "SH")
all_imgs <- merged_df %>% group_split(merged_df)


img_means <- c()
for (k in k_ns) {
  for (i in 1:length(all_imgs)) {
    current_img <- all_imgs[[i]]
    current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
    # Each row in an image is a cell
    for (r in 1:nrow(current_img)) {
      my_obs <- current_img[r, ]
      my_x <- filter(current_img, id != my_obs$id)
      current_cell_neighbor_mean <- nearest_neighbors(my_x[, 7:8], my_obs[, 7:8], num_neighbors = k, distance_func = euclidean_distance, apply_intensity = TRUE, p_only = TRUE, calc_mean_intensity = TRUE)
      img_means <- c(img_means, current_cell_neighbor_mean)
      current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
    }
    write.csv(current_img, paste0("Outputs/knn_analysis/data/img_", i, "_knn_", k, "_df_16_bit_mean_neighborhood_analysis.csv"))
    img_means <- c()
  }

  all_dfs <- vector(mode = "list", length = 8)
  for (i in 1:length(all_imgs)) {
    current_df <- read.csv(paste0("Outputs/knn_analysis/data/img_", i, "_knn_", k, "_df_16_bit_mean_neighborhood_analysis.csv"))
    all_dfs[[i]] <- current_df
  }

  mean_neighbor_df <- bind_rows(all_dfs)

  mean_neighbor_df$condition_spec <- factor(mean_neighbor_df$condition_spec, levels = c("NH", "SH"))

  # Filtering all cells that have NA as their mean neighborhood intensity (because all neighbors were N annotated)
  mean_neighbor_df <- filter(mean_neighbor_df, !is.na(mean_neighbor_df$positive_neighborhood_mean))

  p1 <- ggscatter(
    data = mean_neighbor_df,
    x = "mean", y = "positive_neighborhood_mean",
    conf.int = FALSE,
    cor.coef = TRUE,
    shape = 21,
    color = "black",
    fill = "mecp2_p",
    alpha = 0.5,
    cor.method = stat_used,
    xlab = "Mean Intensity of Cells",
    ylab = "Mean MECP2+\nNeighborhood Intensity",
    ellipse = TRUE,
    mean.point = TRUE,
    cor.coeff.args = list(method = stat_used, label.x = 3000)
  )

  p2 <- ggpar(p1,
    legend = "right",
    legend.title = "MECP2\nStatus",
    palette = c("#4682b4", "#F4A460"),
    main = paste0("KNN = ", k, " | All Conditions & Images | ", stat_used),
    font.main = c(16, "bold"),
    font.x = c(14, "bold"),
    font.y = c(14, "bold")
  )

  p3 <- p2 + stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")),
    label.x = 3000,
    label.y = 3500
  )

  plots <- list()


  for (c in unique(mean_neighbor_df$condition_spec)) {
    current_cond <- filter(mean_neighbor_df, condition_spec == c)
    current_cond_p <- filter(current_cond, mecp2_p == "P")
    p1 <- ggscatter(
      data = current_cond_p,
      x = "mean", y = "positive_neighborhood_mean",
      conf.int = TRUE,
      cor.coef = TRUE,
      cor.coeff.args = list(
        method = "spearman",
        label.x = 2000, label.sep = "\n",
        cor.coef.name = "rho"
      ),
      parse = TRUE,
      cor.coef.size = 10,
      shape = 21,
      size = 2.5,
      add = fit_line,
      add.params = list(
        color = "black",
        fill = "grey"
      ),
      repel = TRUE,
      label.rectangle = TRUE,
      color = "black",
      fill = "black",
      alpha = 1,
      cor.method = stat_used,
      xlab = "Mean Intensity of Cells",
      ylab = "Mean MECP2+\nNeighborhood Intensity",
      ellipse = FALSE,
      mean.point = FALSE
    )

    # p2 for the single annotation context
    p2 <- ggpar(p1,
      title = paste0("K = ", k, " | ", c),
      font.main = c(20, "bold"),
      font.x = c(18, "bold"),
      font.y = c(18, "bold"),
      ggtheme = theme(plot.title = element_text(hjust = 0.5))
    )

    p2 <- p2 +
      theme(
        axis.line = element_line(linewidth = 1.5, lineend = "round"),
        axis.text = element_text(size = 18), axis.ticks = element_line(linewidth = 0.2),
        plot.subtitle = element_text(face = "italic")
      ) +
      scale_x_continuous(limits = c(0, 4500)) +
      scale_y_continuous(limits = c(0, 2500))

    # For adding density-based contours. Comment out if not wanting countours
    p2 <- p2 +
      geom_density2d(aes(colour = ..level..), linewidth = 0.7, n = 100) +
      scale_colour_gradient(low = "blue", high = "red") +
      theme(legend.position = "none")



    # Change to p2 when in a single annotation context, p5 otherwise
    ggsave(plot = p2, filename = paste0("knn_", k, "_", c, "_positive_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_k1_k15_analysis.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/k_1_to_k_15_analysis/", device = file_type_used, dpi = 600, width = 8, height = 8, units = "in")

    # Change to p2 for single annotation case, p5 otherwise
    plots[[paste0(c)]] <- p2
  }

  # Combo plot
  combo_plot <- ggarrange(
    plots$NW,
    plots$SW,
    plots$NH,
    plots$SH,
    ncol = 2,
    nrow = 2,
    labels = "AUTO",
    align = "hv",
    legend = "none",
    common.legend = TRUE,
    font.label = list(
      size = 18,
      face = "bold"
    )
  )

  ggsave(plot = combo_plot, filename = paste0("knn_", k, "_combo_plot_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_with_contours_k1_k15_analysis.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/k_1_to_k_15_analysis/", device = file_type_used, dpi = 600, width = 16, height = 16, units = "in", bg = "white")
}
```

```{r making the k1 to k15 plot}
k_ns <- seq(1, 15, 1)
rhos_nh <- c(0.25, 0.42, 0.36, 0.33, 0.37, 0.36, 0.39, 0.38, 0.34, 0.36, 0.39, 0.38, 0.38, 0.35, 0.36)
rhos_sh <- c(0.19, 0.34, 0.33, 0.33, 0.34, 0.34, 0.34, 0.34, 0.37, 0.37, 0.37, 0.40, 0.39, 0.39, 0.38)
all_rhos <- c(rhos_nh, rhos_sh)

df <- data.frame(k = k_ns, rhos = all_rhos, condition = rep(c("NH", "SH"), each = 15))
df$k <- as.factor(df$k)


p1 <- ggplot(data = df, aes(x = k, y = rhos)) +
  geom_col(width = 0.8, fill = "steelblue") +
  theme(
    panel.background = element_blank(),
    axis.title = element_text(size = 18, face = "bold"),
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
    axis.line = element_line(color = "black", linewidth = 1.5),
    axis.ticks.length = unit(0.2, units = "cm"),
    axis.text = element_text(size = 16),
    legend.position = "bottom",
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 16),
    strip.text = element_text(size = 16, face = "bold"),
  ) +
  geom_text(aes(label = round(rhos, 2)), vjust = -0.5, size = 8) +
  facet_wrap(~condition, ncol = 1, nrow = 2) +
  xlab("K") +
  ylab(expression(rho)) +
  scale_color_discrete("Condition") +
  scale_y_continuous(expand = c(0, 0), limits = c(0.0, 0.48))

p1

ggsave(plot = p1, filename = "rhos_across_k_1_to_15_nh_sh.svg", path = "Outputs/knn_analysis/plots/", device = "svg", height = 9, width = 16, units = "in", dpi = 600)

ggsave(plot = p1, filename = "rhos_across_k_1_to_15_nh_sh.png", path = "Outputs/knn_analysis/plots/", device = "png", height = 9, width = 16, units = "in", dpi = 600)
```

```{r distribution of random rhos histogram analysis}
k_n <- 5

naive_df_wt <- read_excel("Data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
# Filtering to just P annotated cells
merged_df <- filter(merged_df, mecp2_p == "P")
# Modify this line to change conditions
merged_df <- filter(merged_df, condition_spec == "NH")
current_cond <- as.character(unique(merged_df$condition_spec))
all_imgs <- merged_df %>% group_split(merged_df)


# Loop for 1000 times
all_rhos_stored <- c()
all_p_values_stored <- c()

for (n in 1:1000) {
  img_means <- c()
  for (i in 1:length(all_imgs)) {
    current_img <- all_imgs[[i]]
    current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
    for (r in 1:nrow(current_img)) {
      my_obs <- current_img[r, ]
      my_x <- filter(current_img, id != my_obs$id)

      current_cell_neighbor_mean <- nearest_neighbors(
        data = my_x[, 7:8],
        observation = my_obs[, 7:8],
        num_neighbors = k_n,
        distance_func = euclidean_distance,
        apply_intensity = TRUE,
        p_only = TRUE,
        random_num_neighbors = TRUE,
        calc_mean_intensity = TRUE,
        intensity_data = my_x
      )
      img_means <- c(img_means, current_cell_neighbor_mean)
      current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
    }

    write.csv(current_img, paste0("Outputs/knn_analysis/data/1000_simulation/", current_cond, "/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis_random_", k_n, "_sample_", n, ".csv"))
    img_means <- c()
  }

  all_dfs <- vector(mode = "list", length = 4)
  for (i in 1:length(all_imgs)) {
    current_df <- read.csv(paste0("Outputs/knn_analysis/data/1000_simulation/", current_cond, "/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis_random_", k_n, "_sample_", n, ".csv"))
    all_dfs[[i]] <- current_df
  }

  mean_neighbor_df <- bind_rows(all_dfs)


  # Calculating rho
  cor_res <- cor.test(x = mean_neighbor_df$mean, y = mean_neighbor_df$positive_neighborhood_mean, method = "spearman")
  current_p <- cor_res$p.value
  current_rho <- as.numeric(as.vector(unlist(cor_res$estimate)))
  all_rhos_stored <- c(current_rho, all_rhos_stored)
  all_p_values_stored <- c(current_p, all_p_values_stored)
}


all_rhos_df <- data.frame(
  k = rep(k_n, times = length(all_rhos_stored)),
  condition = rep(unique(mean_neighbor_df$condition_spec), times = length(all_rhos_stored)),
  rho = all_rhos_stored, p_value = all_p_values_stored
)

write.csv(all_rhos_df, file = paste0("Outputs/knn_analysis/data/1000_simulation/Finished_files/finished_", unique(mean_neighbor_df$condition_spec), "_df_for_plot_k_", k_n, ".csv"))
```

```{r histograms by condition}
# Function to easily read and combine the finished files
read_files <- function(folder_path, pattern) {
  # Get a list of all files in the folder that match the pattern
  file_list <- list.files(path = folder_path, pattern = pattern, full.names = TRUE)

  # Read in all CSV files and combine into a single dataframe
  data <- do.call(rbind, lapply(file_list, read.csv))

  return(data)
}



all_rho_data <- read_files(folder_path = "Outputs/knn_analysis/data/1000_simulation/Finished_files", pattern = "*.csv")

all_rho_data$condition <- factor(all_rho_data$condition, levels = c("NW", "NH", "SW", "SH"))

p1 <- ggplot(data = all_rho_data, aes(x = rho)) +
  geom_histogram() +
  theme(
    panel.background = element_blank(),
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    axis.ticks = element_line(linewidth = 1.25),
    axis.ticks.length = unit(0.2, units = "cm"),
    strip.text = element_text(size = 18, face = "bold"),
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
    axis.line = element_line(colour = "black", linewidth = 1.25)
  ) +
  ggtitle(paste0("K = ", k_n, " | ", length(all_rhos_stored))) +
  xlab(expression(rho)) +
  ylab("Count") +
  scale_y_continuous(expand = c(0, 0)) +
  facet_wrap(~condition, nrow = 2, ncol = 2)

ggsave(plot = p1, filename = "all_conditions_random_knn_5_vs_rho_histogram.svg", device = "svg", width = 8, height = 8, units = "in", path = "Outputs/knn_analysis/plots/")
```

```{r 3d  KNN analysis}
threed_data <- read.csv("Data/Jacob/3d6WOdataset.csv")
threed_data <- threed_data %>%
  select(image, Mean, CX..pix., CY..pix., CZ..pix.) %>%
  rename_all(tolower) %>%
  rename(
    x = cx..pix.,
    y = cy..pix.,
    z = cz..pix.
  ) %>%
  mutate(hemisphere = str_extract(image, "(LH|RH)")) %>%
  mutate(condition = str_extract(image, "(NW|NH|SW|SH)")) %>%
  mutate(mecp2_p = "P") %>%
  mutate(id = 1:nrow(.))


k_n <- 5

# Modify this line to change conditions
threed_data <- filter(threed_data, condition == "NW")
current_cond <- as.character(unique(threed_data$condition))
threed_data <- threed_data %>% group_by(image)
all_imgs <- threed_data %>% group_split(threed_data)


# Loop for 1000 times
all_rhos_stored <- c()
all_p_values_stored <- c()

for (n in 1:1000) {
  img_means <- c()
  for (i in 1:length(all_imgs)) {
    current_img <- all_imgs[[i]]
    current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
    for (r in 1:nrow(current_img)) {
      my_obs <- current_img[r, ]
      my_x <- current_img %>% filter(id != my_obs$id)
      current_cell_neighbor_mean <- nearest_neighbors(
        data = my_x[, 3:5],
        observation = my_obs[, 3:5],
        num_neighbors = k_n,
        distance_func = function(a, b) euclidean_distance_3d(a = my_obs$x, b = my_obs$y, c = my_obs$z),
        apply_intensity = TRUE,
        p_only = TRUE,
        random_num_neighbors = TRUE,
        calc_mean_intensity = TRUE,
        intensity_data = my_x
      )
      img_means <- c(img_means, current_cell_neighbor_mean)
      current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
    }

    write.csv(current_img, paste0("Outputs/knn_analysis/data/1000_simulation/", current_cond, "/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis_random_", k_n, "_sample_", n, "_3d_checked.csv"))
    img_means <- c()
  }

  all_dfs <- vector(mode = "list", length = 4)
  for (i in 1:length(all_imgs)) {
    current_df <- read.csv(paste0("Outputs/knn_analysis/data/1000_simulation/", current_cond, "/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis_random_", k_n, "_sample_", n, "_3d_checked.csv"))
    all_dfs[[i]] <- current_df
  }

  mean_neighbor_df <- bind_rows(all_dfs)


  # Calculating rho
  cor_res <- cor.test(x = mean_neighbor_df$mean, y = mean_neighbor_df$positive_neighborhood_mean, method = "spearman")
  current_p <- cor_res$p.value
  current_rho <- as.numeric(as.vector(unlist(cor_res$estimate)))
  all_rhos_stored <- c(current_rho, all_rhos_stored)
  all_p_values_stored <- c(current_p, all_p_values_stored)
}


all_rhos_df <- data.frame(
  k = rep(k_n, times = length(all_rhos_stored)),
  condition = rep(unique(mean_neighbor_df$condition), times = length(all_rhos_stored)),
  rho = all_rhos_stored, p_value = all_p_values_stored
)

write.csv(all_rhos_df, file = paste0("Outputs/knn_analysis/data/1000_simulation/Finished_files/finished_", unique(mean_neighbor_df$condition), "_df_for_plot_k_", k_n, "_3d_checked.csv"))
```


```{r histogram for 3d data}
all_rho_data <- read_files(folder_path = "Outputs/knn_analysis/data/1000_simulation/Finished_files", pattern = "*_3d.csv")

all_rho_data$condition <- factor(all_rho_data$condition, levels = c("NW", "NH"))

# Define custom labels
custom_labels <- c(
  "3" = "K = 3",
  "5" = "K = 5",
  "NW" = "NW",
  "NH" = "NH"
)


p1 <- ggplot(data = all_rho_data, aes(x = rho)) +
  geom_histogram() +
  theme(
    panel.background = element_blank(),
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    axis.ticks = element_line(linewidth = 1.25),
    axis.ticks.length = unit(0.2, units = "cm"),
    strip.text = element_text(size = 18, face = "bold"),
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
    axis.line = element_line(colour = "black", linewidth = 1.25)
  ) +
  xlab(expression(rho)) +
  ylab("Count") +
  scale_y_continuous(expand = c(0, 0)) +
  facet_grid(k ~ condition, labeller = as_labeller(custom_labels))

ggsave(plot = p1, filename = "all_conditions_random_knn_vs_rho_histogram_3d.svg", device = "svg", width = 8, height = 8, units = "in", path = "Outputs/knn_analysis/plots/")
```

```{r KNN analysis for 3d data}
p_score <- 0
n_score <- 0
k_n <- 5
file_type_used <- "png"
# pearson, kendall, or spearman
stat_used <- "spearman"
# reg.line or loess
fit_line <- "reg.line"
using_intensity <- FALSE


threed_data <- read.csv("Data/Jacob/3d6WOdataset.csv")
threed_data <- threed_data %>%
  select(image, Mean, CX..pix., CY..pix., CZ..pix.) %>%
  rename_all(tolower) %>%
  rename(
    x = cx..pix.,
    y = cy..pix.,
    z = cz..pix.
  ) %>%
  mutate(hemisphere = str_extract(image, "(LH|RH)")) %>%
  mutate(condition = str_extract(image, "(NW|NH|SW|SH)")) %>%
  mutate(mecp2_p = "P") %>%
  mutate(id = 1:nrow(.))

threed_data <- threed_data %>% group_by(image)
all_imgs <- threed_data %>% group_split(threed_data)


img_means <- c()
for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
  # Each row in an image is a cell
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)
    current_cell_neighbor_mean <- nearest_neighbors(my_x[, 3:5], my_obs[, 3:5], num_neighbors = k_n, distance_func = function(a, b) euclidean_distance_3d(a = my_obs$x, b = my_obs$y, c = my_obs$z), intensity_data = my_x, p_only = TRUE, calc_mean_intensity = TRUE, apply_intensity = TRUE)
    img_means <- c(img_means, current_cell_neighbor_mean)
    current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/3d_data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis.csv"))
  img_means <- c()
}



all_dfs <- vector(mode = "list", length = 16)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/3d_data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis.csv"))
  all_dfs[[i]] <- current_df
}

mean_neighbor_df <- bind_rows(all_dfs)

mean_neighbor_df$condition_spec <- factor(mean_neighbor_df$condition, levels = c("NW", "NH"))


p1 <- ggscatter(
  data = mean_neighbor_df,
  x = "mean", y = "positive_neighborhood_mean",
  conf.int = FALSE,
  cor.coef = TRUE,
  shape = 21,
  color = "black",
  fill = "mecp2_p",
  alpha = 0.5,
  cor.method = stat_used,
  xlab = "Mean Intensity of Cells",
  ylab = "Mean MECP2+\nNeighborhood Intensity",
  ellipse = TRUE,
  mean.point = TRUE,
  cor.coeff.args = list(method = stat_used, label.x = 3000)
)

p2 <- ggpar(p1,
  legend = "right",
  legend.title = "MECP2\nStatus",
  palette = c("#4682b4", "#F4A460"),
  main = paste0("KNN = ", k_n, " | All Conditions & Images | ", stat_used),
  font.main = c(16, "bold"),
  font.x = c(14, "bold"),
  font.y = c(14, "bold")
)

p3 <- p2 + stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "~`,`~")),
  label.x = 3000,
  label.y = 3500
)
```

```{r combo correlation plot for 3d data}
plots <- list()


for (c in unique(mean_neighbor_df$condition)) {
  current_cond <- filter(mean_neighbor_df, condition == c)
  current_cond_p <- filter(current_cond, mecp2_p == "P")
  p1 <- ggscatter(
    data = current_cond_p,
    x = "mean", y = "positive_neighborhood_mean",
    conf.int = TRUE,
    cor.coef = TRUE,
    cor.coeff.args = list(
      method = "spearman",
      label.x = 2000, label.y = 1000, label.sep = "\n",
      cor.coef.name = "rho"
    ),
    parse = TRUE,
    cor.coef.size = 10,
    shape = 21,
    size = 2.5,
    add = fit_line,
    add.params = list(
      color = "black",
      fill = "grey"
    ),
    repel = TRUE,
    label.rectangle = TRUE,
    color = "black",
    fill = "black",
    alpha = 1,
    cor.method = stat_used,
    xlab = "Mean Intensity of Cells",
    ylab = "Mean MECP2+\nNeighborhood Intensity",
    ellipse = FALSE,
    mean.point = FALSE
  )

  # p2 for the single annotation context
  p2 <- ggpar(p1,
    title = paste0("K = ", k_n, " | ", c),
    font.main = c(20, "bold"),
    font.x = c(18, "bold"),
    font.y = c(18, "bold"),
    ggtheme = theme(plot.title = element_text(hjust = 0.5))
  )

  p2 <- p2 +
    theme(
      axis.line = element_line(linewidth = 1.5, lineend = "round"),
      axis.text = element_text(size = 18), axis.ticks = element_line(linewidth = 0.2),
      plot.subtitle = element_text(face = "italic")
    )

  # For adding density-based contours. Comment out if not wanting countours
  p2 <- p2 +
    geom_density2d(aes(colour = ..level..), linewidth = 0.7, n = 100) +
    scale_colour_gradient(low = "blue", high = "red") +
    theme(legend.position = "none")

  # Change to p2 when in a single annotation context, p5 otherwise
  ggsave(plot = p2, filename = paste0("knn_", k_n, "_", c, "_positive_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_3d.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = file_type_used, dpi = 600, width = 8, height = 8, units = "in")

  # Change to p2 for single annotation case, p5 otherwise
  plots[[paste0(c)]] <- p2
}

# Combo plot
combo_plot <- ggarrange(
  plots$NW,
  plots$NH,
  ncol = 2,
  nrow = 1,
  labels = "AUTO",
  align = "hv",
  legend = "none",
  common.legend = TRUE,
  font.label = list(
    size = 18,
    face = "bold"
  )
)

ggsave(plot = combo_plot, filename = paste0("knn_", k_n, "_combo_plot_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_with_contours_3d.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = file_type_used, dpi = 600, width = 12, height = 12, units = "in", bg = "white")
```


# 2D violin plot of distribution
```{r 2d data volin plot distribution}
naive_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "WT")
naive_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "HET")
sur_df_wt <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surWT")
sur_df_het <- read_excel("Data/Old data/Jacob/16bitdata.xlsx", sheet = "surHET")

colnames(naive_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(naive_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_wt) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")
colnames(sur_df_het) <- c("image", "roi", "area", "mean", "mecp2_p", "id", "x", "y")

naive_df_wt$condition <- rep("WT", nrow(naive_df_wt))
naive_df_het$condition <- rep("HET", nrow(naive_df_het))
sur_df_wt$condition <- rep("WT", nrow(sur_df_wt))
sur_df_het$condition <- rep("HET", nrow(sur_df_het))

merged_df <- bind_rows(naive_df_wt, naive_df_het, sur_df_wt, sur_df_het)
merged_df$condition_spec <- rep(c("NW", "NH", "SW", "SH"), c(223, 259, 249, 269))
merged_df$condition_spec <- factor(merged_df$condition_spec, levels = c("NW", "SW", "NH", "SH"))
# Removing a single image because it just is grouped by itself
merged_df <- filter(merged_df, image != "MAX_16-bit_NH-LW8-2.2-Map126_561-60_G150_E100_z13-23")
merged_df <- merged_df %>% group_by(image)
all_imgs <- merged_df %>% group_split(merged_df)

k_n <- 5

all_dfs <- vector(mode = "list", length = 16)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0(
    "Outputs/knn_analysis/data/img_", i,
    "_knn_", k_n,
    "_df_16_bit_mean_neighborhood_analysis.csv"
  ))
  all_dfs[[i]] <- current_df
}

mean_neighbor_df <- bind_rows(all_dfs)


# Trying a slightly different analysis with doing the same scatter plot stuff as the color coding but for the violin plots
all_imgs <- list()
counter <- 1
mean_neighbor_df_simplified <- mean_neighbor_df
mean_neighbor_df_simplified <- mean_neighbor_df_simplified %>%
  mutate(image = match(image, unique(image)))

for (i in unique(mean_neighbor_df_simplified$condition_spec)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition_spec == i)
  current_cond$image <- as.factor(current_cond$image)

  # Test for normality using Shapiro-Wilk test
  shapiro_test <- shapiro.test(current_cond$positive_neighborhood_mean)
  if (shapiro_test$p.value >= 0.05) {
    # Data is normally distributed
    print("Data is normally distributed")

    # Perform Levene's test for homogeneity of variances
    levene_test <- leveneTest(positive_neighborhood_mean ~ image, data = current_cond)
    print(levene_test)

    p_value <- levene_test$"Pr(>F)"[1] # Get the p-value from the test
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = FALSE, digits = 3)), "NS")
  } else {
    # Data is not normally distributed
    print("Data is not normally distributed")

    # Perform Fligner-Killeen test for homogeneity of variances
    fligner_test <- fligner.test(positive_neighborhood_mean ~ image, data = current_cond)
    print(fligner_test)
    
    
    kw_test <- kruskal.test(positive_neighborhood_mean ~ image, data = current_cond)
    print(kw_test)

    p_value <- fligner_test$p.value
    p_value_kw <- kw_test$p.value
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = TRUE, digits = 3)), "NS")
     p_value_text <- ifelse(p_value_kw < 0.05, paste0("p = ", format(p_value_kw, scientific = TRUE, digits = 3)), "NS")
  }



  p1 <- ggplot(aes(x = image, y = positive_neighborhood_mean), data = current_cond) +
    geom_violin(draw_quantiles = c(0.25, 0.50, 0.75)) +
    geom_sina(aes(colour = image))+
    theme(
      panel.background = element_blank(),
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      axis.ticks.length = unit(0.2, units = "cm"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      axis.line = element_line(color = "black", lineend = "round", linewidth = 1.25),
      legend.title = element_blank(),
      legend.text = element_blank(),
      legend.key = element_blank(),
      legend.position = "none"
    ) +
    ggtitle(paste0("K = 5 | ", current_cond$condition_spec, " | ", p_value_text)) +
    xlab("Image") +
    ylab("+ Neighborhood Mean") +
    coord_flip()
  all_imgs[[counter]] <- p1
  counter <- counter + 1
}



p2 <- ggarrange(all_imgs[[2]],
  all_imgs[[1]],
  all_imgs[[3]],
  all_imgs[[4]],
  ncol = 2,
  nrow = 2,
  align = "hv",
  labels = "AUTO"
)

# overall_title <- "+ Neighborhood Mean (Image and Condition)"
# p2 <- annotate_figure(p2, top = text_grob(overall_title,
#   face = "bold", size = 22
# ))


ggsave(p2, filename = "positive_neighborhood_mean_violin_plot_by_cond_and_img_with_p_values_kw.png", device = "png", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white")

for (i in 1:length(all_imgs)){
  ggsave(all_imgs[[i]], filename = paste0("positive_neighborhood_mean_violin_plot_by_cond_and_img_with_p_values_kw_",i,".svg"), device = "svg", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white" )
}
```


# 3D data violin plot
```{r 3d data volin plot distribution initial 6WO data}
threed_data <- read.csv("Data/Old data/Jacob/3d6WOdataset.csv")
threed_data <- threed_data %>%
  select(image, Mean, CX..pix., CY..pix., CZ..pix.) %>%
  rename_all(tolower) %>%
  rename(
    x = cx..pix.,
    y = cy..pix.,
    z = cz..pix.
  ) %>%
  mutate(hemisphere = str_extract(image, "(LH|RH)")) %>%
  mutate(condition = str_extract(image, "(NW|NH|SW|SH)")) %>%
  mutate(mecp2_p = "P") %>%
  mutate(id = 1:nrow(.))

threed_data <- threed_data %>% group_by(image)
all_imgs <- threed_data %>% group_split(threed_data)


img_means <- c()
for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
  # Each row in an image is a cell
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)
    current_cell_neighbor_mean <- nearest_neighbors(my_x[, 3:5], my_obs[, 3:5], num_neighbors = k_n, distance_func = function(a, b) euclidean_distance_3d(a = my_obs$x, b = my_obs$y, c = my_obs$z), intensity_data = my_x, p_only = TRUE, calc_mean_intensity = TRUE, apply_intensity = TRUE)
    img_means <- c(img_means, current_cell_neighbor_mean)
    current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/3d_data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis.csv"))
  img_means <- c()
}



all_dfs <- vector(mode = "list", length = 16)
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/3d_data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis.csv"))
  all_dfs[[i]] <- current_df
}

mean_neighbor_df <- bind_rows(all_dfs)


# Trying a slightly different analysis with doing the same scatter plot stuff as the color coding but for the violin plots
all_imgs <- list()
counter <- 1
mean_neighbor_df_simplified <- mean_neighbor_df
mean_neighbor_df_simplified <- mean_neighbor_df_simplified %>%
  mutate(image = match(image, unique(image)))

for (i in unique(mean_neighbor_df_simplified$condition)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition == i)
  current_cond$image <- as.factor(current_cond$image)

  # Test for normality using Shapiro-Wilk test
  shapiro_test <- shapiro.test(current_cond$positive_neighborhood_mean)
  if (shapiro_test$p.value >= 0.05) {
    # Data is normally distributed
    print("Data is normally distributed")

    # Perform Levene's test for homogeneity of variances
    levene_test <- leveneTest(positive_neighborhood_mean ~ image, data = current_cond)
    print(levene_test)

    p_value <- levene_test$"Pr(>F)"[1] # Get the p-value from the test
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = FALSE, digits = 3)), "NS")
  } else {
    # Data is not normally distributed
    print("Data is not normally distributed")

    # Perform Fligner-Killeen test for homogeneity of variances
    fligner_test <- fligner.test(positive_neighborhood_mean ~ image, data = current_cond)
    print(fligner_test)
    
    
    kw_test <- kruskal.test(positive_neighborhood_mean ~ image, data = current_cond)
    print(kw_test)

    p_value <- fligner_test$p.value
    p_value_kw <- kw_test$p.value
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = TRUE, digits = 3)), "NS")
    # p_value_text <- ifelse(p_value_kw < 0.05, paste0("p = ", format(p_value_kw, scientific = TRUE, digits = 3)), "NS")
  }



  p1 <- ggplot(aes(x = image, y = positive_neighborhood_mean), data = current_cond) +
    geom_violin(draw_quantiles = c(0.25, 0.50, 0.75)) +
    geom_sina(aes(colour = image))+
    theme(
      panel.background = element_blank(),
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      axis.ticks.length = unit(0.2, units = "cm"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      axis.line = element_line(color = "black", lineend = "round", linewidth = 1.25),
      legend.title = element_blank(),
      legend.text = element_blank(),
      legend.key = element_blank(),
      legend.position = "none"
    ) +
    ggtitle(paste0("K = 5 | ", current_cond$condition, " | ", p_value_text, " | 3D")) +
    xlab("Image") +
    ylab("+ Neighborhood Mean") +
    coord_flip()
  all_imgs[[counter]] <- p1
  counter <- counter + 1
}



p2 <- ggarrange(all_imgs[[2]],
  all_imgs[[1]],
  ncol = 2,
  nrow = 1,
  align = "hv",
  labels = "AUTO"
)


# Saving combo plot as PNG
ggsave(p2, filename = "positive_neighborhood_mean_violin_plot_by_cond_and_img_with_p_values_fk_3d.png", device = "png", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white")

# Saving each individual plot as SVG
for (i in 1:length(all_imgs)){
  ggsave(all_imgs[[i]], filename = paste0("positive_neighborhood_mean_violin_plot_by_cond_and_img_with_p_values_fk_3d_",i,".svg"), device = "svg", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white" )
}
```

```{r 3d data volin plot distribution complete 6WO data}
threed_data <- read.csv("Data/Old data/Jacob/3D_MECP2_6WO_combined_dataset.csv")
threed_data <- threed_data %>%
  select(Filename, Mean, CX..pix., CY..pix., CZ..pix.) %>%
  rename_all(tolower) %>%
  rename(
    x = cx..pix.,
    y = cy..pix.,
    z = cz..pix.
  ) %>%
  mutate(hemisphere = str_extract(filename, "(LH|RH)")) %>%
  mutate(condition = str_extract(filename, "(NW|NH|SW|SH)")) %>%
  mutate(mecp2_p = "P") %>%
  mutate(id = 1:nrow(.))

threed_data <- threed_data %>% group_by(filename)
all_imgs <- threed_data %>% group_split(threed_data)


img_means <- c()
for (i in 1:length(all_imgs)) {
  current_img <- all_imgs[[i]]
  current_img$positive_neighborhood_mean <- rep(0, nrow(current_img))
  # Each row in an image is a cell
  for (r in 1:nrow(current_img)) {
    my_obs <- current_img[r, ]
    my_x <- filter(current_img, id != my_obs$id)
    current_cell_neighbor_mean <- nearest_neighbors(my_x[, 3:5], my_obs[, 3:5], num_neighbors = k_n, distance_func = function(a, b) euclidean_distance_3d(a = my_obs$x, b = my_obs$y, c = my_obs$z), intensity_data = my_x, p_only = TRUE, calc_mean_intensity = TRUE, apply_intensity = TRUE)
    img_means <- c(img_means, current_cell_neighbor_mean)
    current_img[r, "positive_neighborhood_mean"] <- current_cell_neighbor_mean
  }
  write.csv(current_img, paste0("Outputs/knn_analysis/data/3d_data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis_complete_dataset.csv"))
  img_means <- c()
}



all_dfs <- vector(mode = "list", length = length(all_imgs))
for (i in 1:length(all_imgs)) {
  current_df <- read.csv(paste0("Outputs/knn_analysis/data/3d_data/img_", i, "_knn_", k_n, "_df_16_bit_mean_neighborhood_analysis_complete_dataset.csv"))
  all_dfs[[i]] <- current_df
}

mean_neighbor_df <- bind_rows(all_dfs)
mean_neighbor_df <- mean_neighbor_df %>%
  mutate(cohort = str_extract(filename, "(051222|051822|052922|102319|112421|121119)")) %>%
  select(-X) %>%
  select(filename, id, mean, cohort, x, y, z, everything())


# Trying a slightly different analysis with doing the same scatter plot stuff as the color coding but for the violin plots
all_imgs <- list()
counter <- 1
mean_neighbor_df_simplified <- mean_neighbor_df
mean_neighbor_df_simplified <- mean_neighbor_df_simplified %>%
  mutate(filename = match(filename, unique(filename)))

for (i in unique(mean_neighbor_df_simplified$condition)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition == i)
  current_cond$filename <- as.factor(current_cond$filename)

  # Test for normality using Shapiro-Wilk test
  shapiro_test <- shapiro.test(current_cond$positive_neighborhood_mean)
  if (shapiro_test$p.value >= 0.05) {
    # Data is normally distributed
    print("Data is normally distributed")

    # Perform Levene's test for homogeneity of variances
    levene_test <- leveneTest(positive_neighborhood_mean ~ filename, data = current_cond)
    print(levene_test)

    p_value <- levene_test$"Pr(>F)"[1] # Get the p-value from the test
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = FALSE, digits = 3)), "NS")
  } else {
    # Data is not normally distributed
    print("Data is not normally distributed")

    # Perform Fligner-Killeen test for homogeneity of variances
    fligner_test <- fligner.test(positive_neighborhood_mean ~ filename, data = current_cond)
    print(fligner_test)
    
    
    kw_test <- kruskal.test(positive_neighborhood_mean ~ filename, data = current_cond)
    print(kw_test)

    p_value <- fligner_test$p.value
    p_value_kw <- kw_test$p.value
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = TRUE, digits = 3)), "NS")
    # p_value_text <- ifelse(p_value_kw < 0.05, paste0("p = ", format(p_value_kw, scientific = TRUE, digits = 3)), "NS")
  }



  p1 <- ggplot(aes(x = filename, y = positive_neighborhood_mean), data = current_cond) +
    geom_violin(draw_quantiles = c(0.25, 0.50, 0.75)) +
    geom_sina(aes(colour = filename))+
    theme(
      panel.background = element_blank(),
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      axis.ticks.length = unit(0.2, units = "cm"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      axis.line = element_line(color = "black", lineend = "round", linewidth = 1.25),
      legend.title = element_blank(),
      legend.text = element_blank(),
      legend.key = element_blank(),
      legend.position = "none"
    ) +
    ggtitle(paste0("K = 5 | ", current_cond$condition, " | ", p_value_text, " | 3D")) +
    xlab("Image") +
    ylab("+ Neighborhood Mean") +
    coord_flip()
  all_imgs[[counter]] <- p1
  counter <- counter + 1
}



p2 <- ggarrange(all_imgs[[4]],
  all_imgs[[3]],
  all_imgs[[2]],
  all_imgs[[1]],
  ncol = 2,
  nrow = 2,
  align = "hv",
  labels = "AUTO"
)


# Saving combo plot as PNG
ggsave(p2, filename = "positive_neighborhood_mean_violin_plot_by_cond_and_img_with_p_values_fk_3d_complete_dataset.png", device = "png", path = "Outputs/", width = 8.5, height = 8.5, dpi = 600, units = "in", bg = "white")

# Saving each individual plot as SVG
for (i in 1:length(all_imgs)){
  ggsave(all_imgs[[i]], filename = paste0("positive_neighborhood_mean_violin_plot_by_cond_and_img_with_p_values_fk_3d_complete_dataset_",i,".svg"), device = "svg", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white" )
}
```


# Doing Mean Intensity by image sina plots 2D
```{r mean intensity by image sina plots 2d}
# Trying a slightly different analysis with doing the same scatter plot stuff as the color coding but for the violin plots
all_imgs <- list()
counter <- 1
mean_neighbor_df_simplified <- mean_neighbor_df
mean_neighbor_df_simplified <- mean_neighbor_df_simplified %>%
  mutate(image = match(image, unique(image)))

for (i in unique(mean_neighbor_df_simplified$condition_spec)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition_spec == i)
  current_cond$image <- as.factor(current_cond$image)

  # Test for normality using Shapiro-Wilk test
  shapiro_test <- shapiro.test(current_cond$mean)
  if (shapiro_test$p.value >= 0.05) {
    # Data is normally distributed
    print("Data is normally distributed")

    # Perform Levene's test for homogeneity of variances
    library(car)
    levene_test <- leveneTest(mean ~ image, data = current_cond)
    print(levene_test)

    p_value <- levene_test$"Pr(>F)"[1] # Get the p-value from the test
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = FALSE, digits = 3)), "NS")
  } else {
    # Data is not normally distributed
    print("Data is not normally distributed")

    # Perform Fligner-Killeen test for homogeneity of variances
    fligner_test <- fligner.test(mean ~ image, data = current_cond)
    print(fligner_test)
    
    
    kw_test <- kruskal.test(mean ~ image, data = current_cond)
    print(kw_test)

    p_value <- fligner_test$p.value
    p_value_kw <- kw_test$p.value
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = TRUE, digits = 3)), "NS")
     p_value_text <- ifelse(p_value_kw < 0.05, paste0("p = ", format(p_value_kw, scientific = TRUE, digits = 3)), "NS")
  }



  p1 <- ggplot(aes(x = image, y = mean), data = current_cond) +
    geom_violin(draw_quantiles = c(0.25, 0.50, 0.75)) +
    geom_sina(aes(colour = image))+
    theme(
      panel.background = element_blank(),
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      axis.ticks.length = unit(0.2, units = "cm"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      axis.line = element_line(color = "black", lineend = "round", linewidth = 1.25),
      legend.title = element_blank(),
      legend.text = element_blank(),
      legend.key = element_blank(),
      legend.position = "none"
    ) +
    ggtitle(paste0("K = 5 | ", current_cond$condition_spec, " | ", p_value_text)) +
    xlab("Image") +
    ylab("Mean Intensity of Cells") +
    coord_flip()
  all_imgs[[counter]] <- p1
  counter <- counter + 1
}



p2 <- ggarrange(all_imgs[[2]],
  all_imgs[[1]],
  all_imgs[[3]],
  all_imgs[[4]],
  ncol = 2,
  nrow = 2,
  align = "hv",
  labels = "AUTO"
)


ggsave(p2, filename = "mean_intensity_violin_plot_by_cond_and_img_with_p_values_kw.png", device = "png", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white")

for (i in 1:length(all_imgs)){
  ggsave(all_imgs[[i]], filename = paste0("mean_intensity_violin_plot_by_cond_and_img_with_p_values_kw_",i,".svg"), device = "svg", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white" )
}
```

# Doing Mean Intensity by image sina plots 3D
```{r mean intensity by image sina plots initial 3d 6WO dataset}
# Trying a slightly different analysis with doing the same scatter plot stuff as the color coding but for the violin plots
all_imgs <- list()
counter <- 1
mean_neighbor_df_simplified <- mean_neighbor_df
mean_neighbor_df_simplified <- mean_neighbor_df_simplified %>%
  mutate(image = match(image, unique(image)))

for (i in unique(mean_neighbor_df_simplified$condition)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition == i)
  current_cond$image <- as.factor(current_cond$image)

  # Test for normality using Shapiro-Wilk test
  shapiro_test <- shapiro.test(current_cond$mean)
  if (shapiro_test$p.value >= 0.05) {
    # Data is normally distributed
    print("Data is normally distributed")

    # Perform Levene's test for homogeneity of variances
    library(car)
    levene_test <- leveneTest(mean ~ image, data = current_cond)
    print(levene_test)

    p_value <- levene_test$"Pr(>F)"[1] # Get the p-value from the test
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = FALSE, digits = 3)), "NS")
  } else {
    # Data is not normally distributed
    print("Data is not normally distributed")

    # Perform Fligner-Killeen test for homogeneity of variances
    fligner_test <- fligner.test(mean ~ image, data = current_cond)
    print(fligner_test)
    
    
    kw_test <- kruskal.test(mean ~ image, data = current_cond)
    print(kw_test)

    p_value <- fligner_test$p.value
    p_value_kw <- kw_test$p.value
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = TRUE, digits = 3)), "NS")
    # p_value_text <- ifelse(p_value_kw < 0.05, paste0("p = ", format(p_value_kw, scientific = TRUE, digits = 3)), "NS")
  }



  p1 <- ggplot(aes(x = image, y = mean), data = current_cond) +
    geom_violin(draw_quantiles = c(0.25, 0.50, 0.75)) +
    geom_sina(aes(colour = image))+
    theme(
      panel.background = element_blank(),
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      axis.ticks.length = unit(0.2, units = "cm"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      axis.line = element_line(color = "black", lineend = "round", linewidth = 1.25),
      legend.title = element_blank(),
      legend.text = element_blank(),
      legend.key = element_blank(),
      legend.position = "none"
    ) +
    ggtitle(paste0("K = 5 | ", current_cond$condition, " | ", p_value_text, " | 3D")) +
    xlab("Image") +
    ylab("Mean Intensity of Cells") +
    coord_flip()
  all_imgs[[counter]] <- p1
  counter <- counter + 1
}



p2 <- ggarrange(all_imgs[[2]],
  all_imgs[[1]],
  ncol = 2,
  nrow = 1,
  align = "hv",
  labels = "AUTO"
)


ggsave(p2, filename = "mean_intensity_violin_plot_by_cond_and_img_with_p_values_fk_3d.png", device = "png", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white")

for (i in 1:length(all_imgs)){
  ggsave(all_imgs[[i]], filename = paste0("mean_intensity_violin_plot_by_cond_and_img_with_p_values_fk_3d_",i,".svg"), device = "svg", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white" )
}
```



```{r 3d data volin plot distribution complete 6WO data mean intensity}
threed_data <- read.csv("Data/Old data/Jacob/3D_MECP2_6WO_combined_dataset.csv")
threed_data <- threed_data %>%
  select(Filename, Mean, CX..pix., CY..pix., CZ..pix.) %>%
  rename_all(tolower) %>%
  rename(
    x = cx..pix.,
    y = cy..pix.,
    z = cz..pix.
  ) %>%
  mutate(hemisphere = str_extract(filename, "(LH|RH)")) %>%
  mutate(condition = str_extract(filename, "(NW|NH|SW|SH)")) %>%
  mutate(mecp2_p = "P") %>%
  mutate(id = 1:nrow(.))

threed_data <- threed_data %>% group_by(filename)
all_imgs <- threed_data %>% group_split(threed_data)


mean_neighbor_df <- bind_rows(all_dfs)
mean_neighbor_df <- mean_neighbor_df %>%
  mutate(cohort = str_extract(filename, "(051222|051822|052922|102319|112421|121119)")) %>%
  select(-X) %>%
  select(filename, id, mean, cohort, x, y, z, everything())


# Trying a slightly different analysis with doing the same scatter plot stuff as the color coding but for the violin plots
all_imgs <- list()
counter <- 1
mean_neighbor_df_simplified <- mean_neighbor_df
mean_neighbor_df_simplified <- mean_neighbor_df_simplified %>%
  mutate(filename = match(filename, unique(filename)))

for (i in unique(mean_neighbor_df_simplified$condition)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition == i)
  current_cond$filename <- as.factor(current_cond$filename)

  # Test for normality using Shapiro-Wilk test
  shapiro_test <- shapiro.test(current_cond$mean)
  if (shapiro_test$p.value >= 0.05) {
    # Data is normally distributed
    print("Data is normally distributed")

    # Perform Levene's test for homogeneity of variances
    levene_test <- leveneTest(mean ~ filename, data = current_cond)
    print(levene_test)

    p_value <- levene_test$"Pr(>F)"[1] # Get the p-value from the test
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = FALSE, digits = 3)), "NS")
  } else {
    # Data is not normally distributed
    print("Data is not normally distributed")

    # Perform Fligner-Killeen test for homogeneity of variances
    fligner_test <- fligner.test(mean ~ filename, data = current_cond)
    print(fligner_test)
    
    
    kw_test <- kruskal.test(mean ~ filename, data = current_cond)
    print(kw_test)

    p_value <- fligner_test$p.value
    p_value_kw <- kw_test$p.value
    p_value_text <- ifelse(p_value < 0.05, paste0("p = ", format(p_value, scientific = TRUE, digits = 3)), "NS")
    # p_value_text <- ifelse(p_value_kw < 0.05, paste0("p = ", format(p_value_kw, scientific = TRUE, digits = 3)), "NS")
  }



  p1 <- ggplot(aes(x = filename, y = mean), data = current_cond) +
    geom_violin(draw_quantiles = c(0.25, 0.50, 0.75)) +
    geom_sina(aes(colour = filename))+
    theme(
      panel.background = element_blank(),
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      axis.ticks.length = unit(0.2, units = "cm"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
      axis.line = element_line(color = "black", lineend = "round", linewidth = 1.25),
      legend.title = element_blank(),
      legend.text = element_blank(),
      legend.key = element_blank(),
      legend.position = "none"
    ) +
    ggtitle(paste0("K = 5 | ", current_cond$condition, " | ", p_value_text, " | 3D")) +
    xlab("Image") +
    ylab("Mean Intensity of Cells") +
    coord_flip()
  all_imgs[[counter]] <- p1
  counter <- counter + 1
}



p2 <- ggarrange(all_imgs[[4]],
  all_imgs[[3]],
  all_imgs[[2]],
  all_imgs[[1]],
  ncol = 2,
  nrow = 2,
  align = "hv",
  labels = "AUTO"
)


# Saving combo plot as PNG
ggsave(p2, filename = "mean_violin_plot_by_cond_and_img_with_p_values_fk_3d_complete_dataset.png", device = "png", path = "Outputs/", width = 8.5, height = 8.5, dpi = 600, units = "in", bg = "white")

# Saving each individual plot as SVG
for (i in 1:length(all_imgs)){
  ggsave(all_imgs[[i]], filename = paste0("mean_violin_plot_by_cond_and_img_with_p_values_fk_3d_complete_dataset_",i,".svg"), device = "svg", path = "Outputs/", width = 8, height = 8, dpi = 600, units = "in", bg = "white" )
}
```


# Color coding 3D scatter plots by image
```{r color coding the scatter plots by image 3d}
plots <- list()
counter <- 1

for (c in unique(mean_neighbor_df_simplified$condition)) {
  current_cond <- filter(mean_neighbor_df_simplified, condition == c)
  current_cond$image <- as.factor(current_cond$filename)
  p1 <- ggscatter(
    data = current_cond,
    x = "mean", y = "positive_neighborhood_mean",
    conf.int = TRUE,
    cor.coef = TRUE,
    cor.coeff.args = list(
      method = "spearman",
      label.x = 0, label.y = 1200, label.sep = ",",
      cor.coef.name = "rho"
    ),
    parse = TRUE,
    cor.coef.size = 10,
    shape = 21,
    size = 2.5,
    add = fit_line,
    add.params = list(
      color = "black",
      fill = "grey"
    ),
    repel = TRUE,
    label.rectangle = TRUE,
    color = "image",
    fill = "image",
    alpha = 1,
    cor.method = stat_used,
    xlab = "Mean Intensity of Cells",
    ylab = "Mean MECP2+\nNeighborhood Intensity",
    ellipse = FALSE,
    mean.point = FALSE
  )

  # p2 for the single annotation context
  p2 <- ggpar(p1,
    title = paste0("K = ", k_n, " | ", c, " | 3D "),
    font.main = c(20, "bold"),
    font.x = c(18, "bold"),
    font.y = c(18, "bold"),
    ggtheme = theme(plot.title = element_text(hjust = 0.5))
  )

  p2 <- p2 +
    theme(
      axis.line = element_line(linewidth = 1.25, lineend = "round"),
      axis.text = element_text(size = 18),
      axis.ticks = element_line(linewidth = 0.2),
      plot.subtitle = element_text(face = "italic"),
      legend.title = element_text(size = 16, face = "bold"),
      legend.text = element_text(size = 14),
      legend.position = "bottom"
    )+
    labs(color = "Image", fill = "Image")


  # Change to p2 when in a single annotation context, p5 otherwise
  ggsave(plot = p2, filename = paste0("knn_", k_n, "_", c, "_positive_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_colored_by_image_3d.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = file_type_used, dpi = 600, width = 8, height = 8, units = "in")

  # Change to p2 for single annotation case, p5 otherwise
  plots[[paste0(c)]] <- p2
  counter <- counter + 1
}

# Combo plot
combo_plot <- ggarrange(
  plots$NW,
  plots$NH,
  plots$SW,
  plots$SH,
  ncol = 2,
  nrow = 2,
  labels = "AUTO",
  align = "hv",
  legend = "right",
  common.legend = FALSE,
  font.label = list(
    size = 18,
    face = "bold"
  )
)


ggsave(plot = combo_plot, filename = paste0("knn_", k_n, "_combo_plot_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_with_contours_colored_by_image_3d.", file_type_used), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = file_type_used, dpi = 600, width = 12, height = 12, units = "in", bg = "white")


for (i in 1:length(plots)){
  ggsave(plot = plots[[i]], filename = paste0("knn_", k_n, "_combo_plot_neighborhood_correlation_analysis_p_cells_only_", stat_used, "_only_p_cells_included_no_contours_colored_by_image_3d",i, ".svg"), path = "Outputs/knn_analysis/plots/correlation_analysis/", device = "svg", dpi = 600, width = 10, height = 10, units = "in", bg = "white" )
}
```

